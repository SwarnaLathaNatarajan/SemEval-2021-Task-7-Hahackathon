{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM_Classification_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY8pJTbC5KVX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import contractions\n",
        "import unicodedata\n",
        "import re\n",
        "import inflect\n",
        "import pickle\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJPgjammMHUt"
      },
      "source": [
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"public_dev.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBjhMLjMOW1"
      },
      "source": [
        "def denoise_text(text):\n",
        "    text = contractions.fix(text)\n",
        "    return text\n",
        "\n",
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def replace_numbers(words):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    p = inflect.engine()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.isdigit():\n",
        "            new_word = p.number_to_words(word)\n",
        "            new_words.append(new_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def normalize_text(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    #words = replace_numbers(words)\n",
        "    words = remove_stopwords(words)\n",
        "    words = stem_words(words)\n",
        "    words = lemmatize_verbs(words)\n",
        "    return words\n",
        "\n",
        "def tokenize(text):\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "def text_prepare(text):\n",
        "    text = denoise_text(text)\n",
        "    text = ' '.join([x for x in normalize_text(tokenize(text))])\n",
        "    return text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZPPCIAkMfHT"
      },
      "source": [
        "df_train['text'] = [text_prepare(x) for x in df_train['text']]\n",
        "df_test['text'] = [text_prepare(x) for x in df_test['text']]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjYWrIdeMi29"
      },
      "source": [
        "def prepare_model_input(X_train, X_test,MAX_NB_WORDS=75000,MAX_SEQUENCE_LENGTH=500):\n",
        "    np.random.seed(7)\n",
        "    text = np.concatenate((X_train, X_test), axis=0)\n",
        "    text = np.array(text)\n",
        "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    pickle.dump(tokenizer, open('text_tokenizer.pkl', 'wb'))\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    word_index = tokenizer.word_index\n",
        "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    print('Found %s unique tokens.' % len(word_index))\n",
        "    indices = np.arange(text.shape[0])\n",
        "    # np.random.shuffle(indices)\n",
        "    text = text[indices]\n",
        "    print(text.shape)\n",
        "    X_train_Glove = text[0:len(X_train), ]\n",
        "    X_test_Glove = text[len(X_train):, ]\n",
        "    embeddings_dict = {}\n",
        "    f = open(\"glove.6B.300d.txt\", encoding=\"utf8\")\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        try:\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "        except:\n",
        "            pass\n",
        "        embeddings_dict[word] = coefs\n",
        "    f.close()\n",
        "    print('Total %s word vectors.' % len(embeddings_dict))\n",
        "    return (X_train_Glove, X_test_Glove, word_index, embeddings_dict)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnzyqyEnM06N"
      },
      "source": [
        "def build_bilstm(word_index, embeddings_dict, nclasses,  MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=300, dropout=0.5, hidden_layer = 3, lstm_node = 32):\n",
        "    # Initialize a sequebtial model\n",
        "    model = Sequential()\n",
        "    # Make the embedding matrix using the embedding_dict\n",
        "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_dict.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            if len(embedding_matrix[i]) != len(embedding_vector):\n",
        "                print(\"could not broadcast input array from shape\", str(len(embedding_matrix[i])),\n",
        "                      \"into shape\", str(len(embedding_vector)), \" Please make sure your\"\n",
        "                                                                \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
        "                exit(1)\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "            \n",
        "    # Add embedding layer\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                                EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=True))\n",
        "    # Add hidden layers \n",
        "    for i in range(0,hidden_layer):\n",
        "        # Add a bidirectional lstm layer\n",
        "        model.add(Bidirectional(LSTM(lstm_node, return_sequences=True, recurrent_dropout=0.2)))\n",
        "        # Add a dropout layer after each lstm layer\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Bidirectional(LSTM(lstm_node, recurrent_dropout=0.2)))\n",
        "    model.add(Dropout(dropout))\n",
        "    # Add the fully connected layer with 256 nurons and relu activation\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    # Add the output layer with softmax activation since we have 2 classes\n",
        "    model.add(Dense(nclasses, activation='softmax'))\n",
        "    # Compile the model using sparse_categorical_crossentropy\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbT69WRBNAsi"
      },
      "source": [
        "**is_humor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNr1sS8PM5AF",
        "outputId": "ad9aa6e6-0912-4f6e-a184-205368e99728"
      },
      "source": [
        "X_train = df_train.text\n",
        "y_train = df_train.is_humor\n",
        "X_test = df_test.text\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "print(\"Preparing model input ...\")\n",
        "X_train_Glove, X_test_Glove, word_index, embeddings_dict = prepare_model_input(X_train,X_test)\n",
        "print(\"Done!\")\n",
        "print(\"Building Model!\")\n",
        "model = build_bilstm(word_index, embeddings_dict, 2)\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing model input ...\n",
            "Found 9625 unique tokens.\n",
            "(9000, 500)\n",
            "Total 340956 word vectors.\n",
            "Done!\n",
            "Building Model!\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 300)          2887800   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 500, 64)           85248     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 500, 64)           24832     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 500, 64)           24832     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 3,064,698\n",
            "Trainable params: 3,064,698\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LU7n9EzNH6k"
      },
      "source": [
        "def get_eval_report(labels, preds):\n",
        "    mcc = matthews_corrcoef(labels, preds)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
        "    precision = (tp)/(tp+fp)\n",
        "    recall = (tp)/(tp+fn)\n",
        "    f1 = (2*(precision*recall))/(precision+recall)\n",
        "    return {\n",
        "        \"mcc\": mcc,\n",
        "        \"true positive\": tp,\n",
        "        \"true negative\": tn,\n",
        "        \"false positive\": fp,\n",
        "        \"false negative\": fn,\n",
        "        \"pricision\" : precision,\n",
        "        \"recall\" : recall,\n",
        "        \"F1\" : f1,\n",
        "        \"accuracy\": (tp+tn)/(tp+tn+fp+fn)\n",
        "    }\n",
        "def compute_metrics(labels, preds):\n",
        "    assert len(preds) == len(labels)\n",
        "    return get_eval_report(labels, preds)\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string], '')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH53_TA2NVDN",
        "outputId": "d3760523-dbd1-4300-d579-a712b68b3806"
      },
      "source": [
        "history = model.fit(X_train_Glove, y_train,\n",
        "                           epochs=5,\n",
        "                           batch_size=128,\n",
        "                           verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "63/63 [==============================] - 361s 6s/step - loss: 0.6051 - accuracy: 0.6695\n",
            "Epoch 2/5\n",
            "63/63 [==============================] - 359s 6s/step - loss: 0.4009 - accuracy: 0.8256\n",
            "Epoch 3/5\n",
            "63/63 [==============================] - 357s 6s/step - loss: 0.2898 - accuracy: 0.8851\n",
            "Epoch 4/5\n",
            "63/63 [==============================] - 356s 6s/step - loss: 0.2025 - accuracy: 0.9261\n",
            "Epoch 5/5\n",
            "63/63 [==============================] - 353s 6s/step - loss: 0.1416 - accuracy: 0.9532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKgKHFyxNWxY",
        "outputId": "d3fa1c0a-b897-437a-8e11-c9ec1c799652"
      },
      "source": [
        "print(\"\\n Evaluating Model ... \\n\")\n",
        "predicted = model.predict_classes(X_test_Glove)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluating Model ... \n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-18-22e5a6263d47>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-22e5a6263d47>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQdOvsDINwnu",
        "outputId": "77b28bb2-8c98-4cc2-abcc-ccf25ee5f695"
      },
      "source": [
        "predicted"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
              "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw_bT2FHOxyO"
      },
      "source": [
        "**Humor_Contro**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "Cz1H1VwbPCtD",
        "outputId": "599868ef-be52-40d7-bde9-8b2f8fb0ebc0"
      },
      "source": [
        "humor = df_train['is_humor']==1\n",
        "df_train_new = df_train[humor]\n",
        "df_train_new.head(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_controversy</th>\n",
              "      <th>offense_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ten best stat nobody ev com clos elev walk roo...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.42</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>man insert advert class wif want next day rece...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>many men tak op beer non op tim bring couch</td>\n",
              "      <td>1</td>\n",
              "      <td>1.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>tell mom hit 1200 twit follow point broth own ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.11</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>ros dead lov fak wed bas fun cak</td>\n",
              "      <td>1</td>\n",
              "      <td>2.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>origin tru on kind also hold glass whit win lo...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>diff mormon man muslim man mormon man get 72 v...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>stop cal 911 run toilet pap ye run toilet pap ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>march streets shout peopl civil disobedy drink...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>mak send creepy ad con two con adult rid tande...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.78</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  ... offense_rating\n",
              "0    1  ...           0.20\n",
              "1    2  ...           1.10\n",
              "2    3  ...           2.40\n",
              "3    4  ...           0.00\n",
              "4    5  ...           0.10\n",
              "7    8  ...           0.00\n",
              "11  12  ...           2.95\n",
              "12  13  ...           0.00\n",
              "13  14  ...           0.20\n",
              "17  18  ...           0.20\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVg4kV3VPheu"
      },
      "source": [
        "df_train = df_train_new.reset_index(drop=True)\n",
        "df_train.humor_controversy = df_train.humor_controversy.astype('int64')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfhwHW2LUzys",
        "outputId": "d0dd8f56-ffd1-45dc-eb88-0a95419bc82a"
      },
      "source": [
        "df_train.dtypes"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                     int64\n",
              "text                  object\n",
              "is_humor               int64\n",
              "humor_rating         float64\n",
              "humor_controversy      int64\n",
              "offense_rating       float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M92YSuSCOslL",
        "outputId": "90e56c2e-dc1a-43e8-f858-c268ac77a3a7"
      },
      "source": [
        "X_train = df_train.text\n",
        "y_train = df_train.humor_controversy\n",
        "X_test = df_test.text\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "print(\"Preparing model input ...\")\n",
        "X_train_Glove, X_test_Glove, word_index, embeddings_dict = prepare_model_input(X_train,X_test)\n",
        "print(\"Done!\")\n",
        "print(\"Building Model!\")\n",
        "model = build_bilstm(word_index, embeddings_dict, 2)\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing model input ...\n",
            "Found 7193 unique tokens.\n",
            "(5932, 500)\n",
            "Total 400000 word vectors.\n",
            "Done!\n",
            "Building Model!\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 300)          2158200   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 500, 64)           85248     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 500, 64)           24832     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 500, 64)           24832     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 2,335,098\n",
            "Trainable params: 2,335,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT-SEQsEOsFr",
        "outputId": "7da9af6a-337a-461f-a37c-db02b2c0059d"
      },
      "source": [
        "history = model.fit(X_train_Glove, y_train,\n",
        "                           epochs=5,\n",
        "                           batch_size=128,\n",
        "                           verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "39/39 [==============================] - 218s 6s/step - loss: 0.6962 - accuracy: 0.4986\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 219s 6s/step - loss: 0.6950 - accuracy: 0.4955\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 221s 6s/step - loss: 0.6930 - accuracy: 0.5093\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 219s 6s/step - loss: 0.6907 - accuracy: 0.5326\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 219s 6s/step - loss: 0.6673 - accuracy: 0.5969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCB-RyruOr5w",
        "outputId": "5de6cbf7-f49c-4cad-cdff-c1c1e373a653"
      },
      "source": [
        "print(\"\\n Evaluating Model ... \\n\")\n",
        "predicted_contro = model.predict_classes(X_test_Glove)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluating Model ... \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2NF6XeLOpr6",
        "outputId": "fbf5bdb4-c890-45bd-bcbc-fcd98ee37f72"
      },
      "source": [
        "predicted_contro"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoISUrznag9a"
      },
      "source": [
        "Humor rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6O4twTBaw8d"
      },
      "source": [
        "def build_bilstm(word_index, embeddings_dict, nclasses,  MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=300, dropout=0.5, hidden_layer = 3, lstm_node = 32):\n",
        "    # Initialize a sequebtial model\n",
        "    model = Sequential()\n",
        "    # Make the embedding matrix using the embedding_dict\n",
        "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_dict.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            if len(embedding_matrix[i]) != len(embedding_vector):\n",
        "                print(\"could not broadcast input array from shape\", str(len(embedding_matrix[i])),\n",
        "                      \"into shape\", str(len(embedding_vector)), \" Please make sure your\"\n",
        "                                                                \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
        "                exit(1)\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "            \n",
        "    # Add embedding layer\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                                EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=True))\n",
        "    # Add hidden layers \n",
        "    # for i in range(0,hidden_layer):\n",
        "    #     # Add a bidirectional lstm layer\n",
        "    #     model.add(Bidirectional(LSTM(lstm_node, return_sequences=True, recurrent_dropout=0.2)))\n",
        "    #     # Add a dropout layer after each lstm layer\n",
        "    #     model.add(Dropout(dropout))\n",
        "    model.add(Bidirectional(LSTM(lstm_node, return_sequences=True, recurrent_dropout=0.2)))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Bidirectional(LSTM(lstm_node, return_sequences=True, recurrent_dropout=0.2)))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Bidirectional(LSTM(lstm_node, return_sequences=True, recurrent_dropout=0.2)))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Bidirectional(LSTM(lstm_node)))\n",
        "    model.add(Dropout(dropout))\n",
        "    # Add the fully connected layer with 256 nurons and relu activation\n",
        "    model.add(Dense(256))\n",
        "    # Add the output layer with softmax activation since we have 2 classes\n",
        "    model.add(Dense(1))\n",
        "    # Compile the model using sparse_categorical_crossentropy\n",
        "    model.compile(loss='mse',\n",
        "                      optimizer='adam')\n",
        "    return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHZmCy6maefW",
        "outputId": "0019b0a7-7eb7-49d5-ea06-753b0ecc97dd"
      },
      "source": [
        "X_train = df_train.text\n",
        "y_train = df_train.is_humor\n",
        "X_test = df_test.text\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "print(\"Preparing model input ...\")\n",
        "X_train_Glove, X_test_Glove, word_index, embeddings_dict = prepare_model_input(X_train,X_test)\n",
        "print(\"Done!\")\n",
        "print(\"Building Model!\")\n",
        "model = build_bilstm(word_index, embeddings_dict, 2)\n",
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing model input ...\n",
            "Found 7193 unique tokens.\n",
            "(5932, 500)\n",
            "Total 400000 word vectors.\n",
            "Done!\n",
            "Building Model!\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 500, 300)          2158200   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 500, 64)           85248     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 500, 64)           24832     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 500, 64)           24832     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 2,334,841\n",
            "Trainable params: 2,334,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffEmN0uUafR8",
        "outputId": "52abacf5-769a-4e28-a638-aba3349cb978"
      },
      "source": [
        "history = model.fit(X_train_Glove, y_train,\n",
        "                           epochs=5,\n",
        "                           batch_size=128,\n",
        "                           verbose=1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "39/39 [==============================] - 201s 5s/step - loss: 0.0855\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 199s 5s/step - loss: 0.0164\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 199s 5s/step - loss: 0.0103\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 201s 5s/step - loss: 0.0073\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 199s 5s/step - loss: 0.0049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBn2qIESafhk",
        "outputId": "6301328e-04c2-457e-f993-9211bfda48ee"
      },
      "source": [
        "print(\"\\n Evaluating Model ... \\n\")\n",
        "predicted_humor_rating = model.predict(X_test_Glove)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluating Model ... \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2GUAxhaafH8",
        "outputId": "beb5177c-664c-4916-c3c8-d9694dc473ff"
      },
      "source": [
        "predicted_humor_rating"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0267284 ],\n",
              "       [1.0285598 ],\n",
              "       [1.0281565 ],\n",
              "       [1.0271419 ],\n",
              "       [1.0281172 ],\n",
              "       [1.0278009 ],\n",
              "       [1.0239993 ],\n",
              "       [1.0274472 ],\n",
              "       [1.0187553 ],\n",
              "       [1.0255113 ],\n",
              "       [1.029445  ],\n",
              "       [0.95011586],\n",
              "       [1.0276228 ],\n",
              "       [1.0010127 ],\n",
              "       [1.0255418 ],\n",
              "       [1.0312151 ],\n",
              "       [1.0271887 ],\n",
              "       [1.0298283 ],\n",
              "       [1.0326444 ],\n",
              "       [1.0287262 ],\n",
              "       [1.0263591 ],\n",
              "       [1.0302538 ],\n",
              "       [1.0322424 ],\n",
              "       [1.0306795 ],\n",
              "       [1.0319101 ],\n",
              "       [1.0275098 ],\n",
              "       [1.0270218 ],\n",
              "       [1.0322769 ],\n",
              "       [1.031878  ],\n",
              "       [1.0276121 ],\n",
              "       [1.0322683 ],\n",
              "       [1.0297045 ],\n",
              "       [1.0322543 ],\n",
              "       [1.0293673 ],\n",
              "       [1.0324184 ],\n",
              "       [1.0259067 ],\n",
              "       [1.0287927 ],\n",
              "       [1.0318953 ],\n",
              "       [1.0231292 ],\n",
              "       [1.0222936 ],\n",
              "       [1.013496  ],\n",
              "       [1.0252734 ],\n",
              "       [1.0298206 ],\n",
              "       [1.0305101 ],\n",
              "       [1.0282704 ],\n",
              "       [1.0299212 ],\n",
              "       [1.0318307 ],\n",
              "       [1.027678  ],\n",
              "       [1.0223204 ],\n",
              "       [1.0262834 ],\n",
              "       [1.0315074 ],\n",
              "       [0.99708533],\n",
              "       [1.0252414 ],\n",
              "       [1.0199237 ],\n",
              "       [1.027121  ],\n",
              "       [1.0296991 ],\n",
              "       [1.0317042 ],\n",
              "       [1.0321709 ],\n",
              "       [1.0331868 ],\n",
              "       [1.0296189 ],\n",
              "       [1.0272182 ],\n",
              "       [1.0249397 ],\n",
              "       [1.026282  ],\n",
              "       [1.0267897 ],\n",
              "       [1.027406  ],\n",
              "       [1.0303142 ],\n",
              "       [1.0116384 ],\n",
              "       [1.0240238 ],\n",
              "       [1.0313774 ],\n",
              "       [1.0291632 ],\n",
              "       [1.0307662 ],\n",
              "       [1.0309094 ],\n",
              "       [1.0242192 ],\n",
              "       [1.0318857 ],\n",
              "       [1.0289208 ],\n",
              "       [1.0331874 ],\n",
              "       [1.0272065 ],\n",
              "       [1.0237353 ],\n",
              "       [1.0302877 ],\n",
              "       [1.0167003 ],\n",
              "       [1.0263833 ],\n",
              "       [1.0310789 ],\n",
              "       [1.0292419 ],\n",
              "       [1.0235949 ],\n",
              "       [1.0309695 ],\n",
              "       [1.0219184 ],\n",
              "       [1.0317646 ],\n",
              "       [1.0335078 ],\n",
              "       [1.0290409 ],\n",
              "       [1.0310551 ],\n",
              "       [1.0237206 ],\n",
              "       [1.0271657 ],\n",
              "       [1.0283388 ],\n",
              "       [1.0176961 ],\n",
              "       [1.0188355 ],\n",
              "       [1.0292913 ],\n",
              "       [1.030272  ],\n",
              "       [1.0336531 ],\n",
              "       [1.0292733 ],\n",
              "       [1.0208837 ],\n",
              "       [1.0312244 ],\n",
              "       [1.0160553 ],\n",
              "       [1.0259196 ],\n",
              "       [1.0191928 ],\n",
              "       [1.027419  ],\n",
              "       [1.0257195 ],\n",
              "       [1.0264622 ],\n",
              "       [1.0277934 ],\n",
              "       [1.0326469 ],\n",
              "       [1.0258994 ],\n",
              "       [1.0296826 ],\n",
              "       [1.0191875 ],\n",
              "       [1.0284787 ],\n",
              "       [1.0282818 ],\n",
              "       [1.0254894 ],\n",
              "       [1.0185044 ],\n",
              "       [1.0213605 ],\n",
              "       [1.022619  ],\n",
              "       [1.0262978 ],\n",
              "       [1.0274287 ],\n",
              "       [1.029668  ],\n",
              "       [1.0265496 ],\n",
              "       [1.0291423 ],\n",
              "       [1.0305947 ],\n",
              "       [1.0333071 ],\n",
              "       [1.0261897 ],\n",
              "       [1.0238127 ],\n",
              "       [1.0317675 ],\n",
              "       [1.0271993 ],\n",
              "       [1.0274245 ],\n",
              "       [1.0319499 ],\n",
              "       [1.0223237 ],\n",
              "       [1.0302368 ],\n",
              "       [1.0175748 ],\n",
              "       [1.0210283 ],\n",
              "       [1.034192  ],\n",
              "       [1.0152112 ],\n",
              "       [1.0284687 ],\n",
              "       [1.031545  ],\n",
              "       [1.031821  ],\n",
              "       [1.0312549 ],\n",
              "       [1.029635  ],\n",
              "       [1.0318279 ],\n",
              "       [1.0274118 ],\n",
              "       [1.0309213 ],\n",
              "       [1.015344  ],\n",
              "       [1.02838   ],\n",
              "       [1.0286465 ],\n",
              "       [1.0287071 ],\n",
              "       [1.0279241 ],\n",
              "       [1.0299572 ],\n",
              "       [1.0293242 ],\n",
              "       [1.0293188 ],\n",
              "       [1.0310032 ],\n",
              "       [1.0308247 ],\n",
              "       [1.0336488 ],\n",
              "       [1.0293585 ],\n",
              "       [1.0057672 ],\n",
              "       [1.0101604 ],\n",
              "       [1.0302612 ],\n",
              "       [1.0264429 ],\n",
              "       [1.0305525 ],\n",
              "       [1.0272251 ],\n",
              "       [1.0294732 ],\n",
              "       [1.0295415 ],\n",
              "       [1.0273689 ],\n",
              "       [1.0251772 ],\n",
              "       [1.0297054 ],\n",
              "       [1.0261072 ],\n",
              "       [1.0157075 ],\n",
              "       [1.0224384 ],\n",
              "       [1.0304042 ],\n",
              "       [1.0129069 ],\n",
              "       [1.0258945 ],\n",
              "       [1.0138366 ],\n",
              "       [1.0327076 ],\n",
              "       [1.0134283 ],\n",
              "       [1.0282997 ],\n",
              "       [1.0340801 ],\n",
              "       [1.0191077 ],\n",
              "       [1.0218039 ],\n",
              "       [1.0317715 ],\n",
              "       [1.025211  ],\n",
              "       [1.0297685 ],\n",
              "       [1.0328379 ],\n",
              "       [1.0156094 ],\n",
              "       [1.0209335 ],\n",
              "       [1.031908  ],\n",
              "       [1.022376  ],\n",
              "       [1.0273384 ],\n",
              "       [1.024337  ],\n",
              "       [1.0250936 ],\n",
              "       [1.0303401 ],\n",
              "       [1.0288388 ],\n",
              "       [1.0272409 ],\n",
              "       [1.0249258 ],\n",
              "       [1.0280063 ],\n",
              "       [1.0251065 ],\n",
              "       [1.0011442 ],\n",
              "       [1.0306798 ],\n",
              "       [1.0237912 ],\n",
              "       [1.0292703 ],\n",
              "       [1.028055  ],\n",
              "       [1.0196432 ],\n",
              "       [1.0314205 ],\n",
              "       [1.0191528 ],\n",
              "       [1.0147693 ],\n",
              "       [1.0203066 ],\n",
              "       [1.0309054 ],\n",
              "       [1.0219328 ],\n",
              "       [1.0300246 ],\n",
              "       [1.0261781 ],\n",
              "       [1.026636  ],\n",
              "       [1.0317302 ],\n",
              "       [1.0323502 ],\n",
              "       [1.0291106 ],\n",
              "       [1.0270919 ],\n",
              "       [1.0298854 ],\n",
              "       [1.0352558 ],\n",
              "       [1.0308143 ],\n",
              "       [1.0284506 ],\n",
              "       [1.0218245 ],\n",
              "       [1.0265557 ],\n",
              "       [1.027002  ],\n",
              "       [1.0342039 ],\n",
              "       [1.0249988 ],\n",
              "       [1.0090202 ],\n",
              "       [1.0259275 ],\n",
              "       [1.0305465 ],\n",
              "       [1.0278313 ],\n",
              "       [1.0268675 ],\n",
              "       [1.0153433 ],\n",
              "       [1.0249782 ],\n",
              "       [1.0279514 ],\n",
              "       [1.0266169 ],\n",
              "       [1.0287672 ],\n",
              "       [1.0221322 ],\n",
              "       [1.0344068 ],\n",
              "       [1.0217744 ],\n",
              "       [1.0281166 ],\n",
              "       [1.0272948 ],\n",
              "       [1.02577   ],\n",
              "       [1.0316781 ],\n",
              "       [1.0285898 ],\n",
              "       [1.0299628 ],\n",
              "       [1.0300233 ],\n",
              "       [0.9962118 ],\n",
              "       [1.0227708 ],\n",
              "       [1.025299  ],\n",
              "       [1.0293025 ],\n",
              "       [1.0261892 ],\n",
              "       [1.0262883 ],\n",
              "       [1.0264237 ],\n",
              "       [1.0086071 ],\n",
              "       [0.9984103 ],\n",
              "       [1.0210859 ],\n",
              "       [1.0148777 ],\n",
              "       [1.0263913 ],\n",
              "       [1.0091244 ],\n",
              "       [1.0313711 ],\n",
              "       [1.035366  ],\n",
              "       [1.0285306 ],\n",
              "       [1.0259073 ],\n",
              "       [1.0322387 ],\n",
              "       [1.025464  ],\n",
              "       [1.0315406 ],\n",
              "       [1.0300916 ],\n",
              "       [1.0215405 ],\n",
              "       [1.029529  ],\n",
              "       [1.0068079 ],\n",
              "       [1.0263156 ],\n",
              "       [1.0315623 ],\n",
              "       [1.0237306 ],\n",
              "       [1.024026  ],\n",
              "       [1.0241264 ],\n",
              "       [1.0175399 ],\n",
              "       [1.0315841 ],\n",
              "       [1.0283734 ],\n",
              "       [1.0274854 ],\n",
              "       [1.0264837 ],\n",
              "       [1.0284401 ],\n",
              "       [1.0214417 ],\n",
              "       [1.0348984 ],\n",
              "       [1.0072839 ],\n",
              "       [1.0203964 ],\n",
              "       [1.0259727 ],\n",
              "       [1.029371  ],\n",
              "       [1.030254  ],\n",
              "       [1.029029  ],\n",
              "       [1.0203665 ],\n",
              "       [1.0268781 ],\n",
              "       [1.0304271 ],\n",
              "       [1.0284415 ],\n",
              "       [1.0324663 ],\n",
              "       [1.0207173 ],\n",
              "       [1.0228559 ],\n",
              "       [1.02787   ],\n",
              "       [1.03028   ],\n",
              "       [1.0268352 ],\n",
              "       [1.0308269 ],\n",
              "       [1.0277786 ],\n",
              "       [1.0323948 ],\n",
              "       [1.0324026 ],\n",
              "       [1.0277747 ],\n",
              "       [1.0280074 ],\n",
              "       [1.0325245 ],\n",
              "       [1.018649  ],\n",
              "       [1.0267885 ],\n",
              "       [1.0287932 ],\n",
              "       [1.0300244 ],\n",
              "       [1.0300361 ],\n",
              "       [1.0266782 ],\n",
              "       [1.0282016 ],\n",
              "       [1.0298547 ],\n",
              "       [1.0219337 ],\n",
              "       [1.0259014 ],\n",
              "       [1.0193499 ],\n",
              "       [1.0315858 ],\n",
              "       [1.0298331 ],\n",
              "       [1.0217919 ],\n",
              "       [1.0310916 ],\n",
              "       [1.0262699 ],\n",
              "       [1.0161645 ],\n",
              "       [1.0250257 ],\n",
              "       [1.0293291 ],\n",
              "       [1.0292645 ],\n",
              "       [1.0292625 ],\n",
              "       [1.0281934 ],\n",
              "       [1.0227523 ],\n",
              "       [1.0291327 ],\n",
              "       [1.0235852 ],\n",
              "       [1.0306102 ],\n",
              "       [1.0270365 ],\n",
              "       [0.98888165],\n",
              "       [1.0265228 ],\n",
              "       [1.0194199 ],\n",
              "       [1.0274576 ],\n",
              "       [1.031786  ],\n",
              "       [1.031007  ],\n",
              "       [1.0290749 ],\n",
              "       [1.0226066 ],\n",
              "       [1.0183758 ],\n",
              "       [1.0262166 ],\n",
              "       [1.0287609 ],\n",
              "       [1.0291473 ],\n",
              "       [1.0294739 ],\n",
              "       [1.0328971 ],\n",
              "       [1.0302942 ],\n",
              "       [1.0280155 ],\n",
              "       [1.025103  ],\n",
              "       [1.0221776 ],\n",
              "       [1.024587  ],\n",
              "       [1.0227413 ],\n",
              "       [1.0294704 ],\n",
              "       [1.0284096 ],\n",
              "       [1.0333697 ],\n",
              "       [1.030592  ],\n",
              "       [1.0285581 ],\n",
              "       [1.0044022 ],\n",
              "       [1.0298921 ],\n",
              "       [1.0265005 ],\n",
              "       [1.030961  ],\n",
              "       [1.031427  ],\n",
              "       [1.018051  ],\n",
              "       [1.0282223 ],\n",
              "       [1.021002  ],\n",
              "       [1.0263088 ],\n",
              "       [1.0321074 ],\n",
              "       [1.0249541 ],\n",
              "       [1.031108  ],\n",
              "       [1.0300062 ],\n",
              "       [1.0101715 ],\n",
              "       [1.0239894 ],\n",
              "       [1.0269891 ],\n",
              "       [1.0272514 ],\n",
              "       [1.0241921 ],\n",
              "       [0.998407  ],\n",
              "       [1.0288501 ],\n",
              "       [1.0339406 ],\n",
              "       [1.028063  ],\n",
              "       [1.0324308 ],\n",
              "       [1.0239627 ],\n",
              "       [1.0272397 ],\n",
              "       [1.0270606 ],\n",
              "       [1.0231897 ],\n",
              "       [1.0264387 ],\n",
              "       [1.030648  ],\n",
              "       [1.0335191 ],\n",
              "       [1.0309366 ],\n",
              "       [1.0297953 ],\n",
              "       [1.0335331 ],\n",
              "       [1.0266091 ],\n",
              "       [1.0233753 ],\n",
              "       [1.0269784 ],\n",
              "       [1.0315462 ],\n",
              "       [1.027817  ],\n",
              "       [1.0294276 ],\n",
              "       [1.0301683 ],\n",
              "       [1.0297348 ],\n",
              "       [1.0298091 ],\n",
              "       [1.0269395 ],\n",
              "       [1.0303289 ],\n",
              "       [1.0284574 ],\n",
              "       [1.0295081 ],\n",
              "       [1.0184743 ],\n",
              "       [1.027251  ],\n",
              "       [1.0260748 ],\n",
              "       [1.0295221 ],\n",
              "       [1.0309978 ],\n",
              "       [1.0298575 ],\n",
              "       [1.0210345 ],\n",
              "       [1.025407  ],\n",
              "       [1.0267245 ],\n",
              "       [1.0310887 ],\n",
              "       [1.0302995 ],\n",
              "       [1.0307467 ],\n",
              "       [1.0222785 ],\n",
              "       [1.0314561 ],\n",
              "       [1.0296018 ],\n",
              "       [1.0272635 ],\n",
              "       [1.0289074 ],\n",
              "       [1.0289973 ],\n",
              "       [1.0246552 ],\n",
              "       [1.0272218 ],\n",
              "       [1.031696  ],\n",
              "       [1.0250758 ],\n",
              "       [1.0314642 ],\n",
              "       [1.0276309 ],\n",
              "       [1.0305297 ],\n",
              "       [1.029056  ],\n",
              "       [1.0294656 ],\n",
              "       [1.0266725 ],\n",
              "       [1.0279579 ],\n",
              "       [1.0312953 ],\n",
              "       [1.0180575 ],\n",
              "       [1.0288292 ],\n",
              "       [1.0312349 ],\n",
              "       [1.0114758 ],\n",
              "       [1.0266346 ],\n",
              "       [1.0283052 ],\n",
              "       [1.031557  ],\n",
              "       [1.020948  ],\n",
              "       [1.0311247 ],\n",
              "       [1.0290736 ],\n",
              "       [1.0232052 ],\n",
              "       [1.0306503 ],\n",
              "       [1.0098855 ],\n",
              "       [1.0278487 ],\n",
              "       [1.0281236 ],\n",
              "       [1.0266956 ],\n",
              "       [1.0265306 ],\n",
              "       [1.0305763 ],\n",
              "       [1.0287325 ],\n",
              "       [1.0274323 ],\n",
              "       [1.029938  ],\n",
              "       [1.0307858 ],\n",
              "       [1.0265237 ],\n",
              "       [1.0334308 ],\n",
              "       [1.0312315 ],\n",
              "       [1.0306581 ],\n",
              "       [1.0071824 ],\n",
              "       [1.0314997 ],\n",
              "       [1.0187008 ],\n",
              "       [1.0154933 ],\n",
              "       [1.0291547 ],\n",
              "       [1.019594  ],\n",
              "       [1.0298744 ],\n",
              "       [1.0288154 ],\n",
              "       [1.031515  ],\n",
              "       [1.0260781 ],\n",
              "       [1.0286995 ],\n",
              "       [1.028255  ],\n",
              "       [1.0289017 ],\n",
              "       [1.0306    ],\n",
              "       [1.004952  ],\n",
              "       [1.02481   ],\n",
              "       [1.0278845 ],\n",
              "       [1.0278872 ],\n",
              "       [1.022356  ],\n",
              "       [1.0316905 ],\n",
              "       [1.0279461 ],\n",
              "       [1.0288258 ],\n",
              "       [1.0316257 ],\n",
              "       [1.0205742 ],\n",
              "       [1.0135862 ],\n",
              "       [1.0288187 ],\n",
              "       [1.0284795 ],\n",
              "       [1.0279931 ],\n",
              "       [1.0250303 ],\n",
              "       [1.0243636 ],\n",
              "       [1.0270859 ],\n",
              "       [1.0321753 ],\n",
              "       [1.0254755 ],\n",
              "       [1.0337876 ],\n",
              "       [1.0280594 ],\n",
              "       [1.0316397 ],\n",
              "       [1.0195276 ],\n",
              "       [1.0266732 ],\n",
              "       [1.0292717 ],\n",
              "       [1.0219438 ],\n",
              "       [1.0310403 ],\n",
              "       [1.0300245 ],\n",
              "       [1.0259571 ],\n",
              "       [1.0297232 ],\n",
              "       [1.0130291 ],\n",
              "       [1.0278529 ],\n",
              "       [1.0161908 ],\n",
              "       [1.0286053 ],\n",
              "       [1.0296632 ],\n",
              "       [1.0257707 ],\n",
              "       [1.0314767 ],\n",
              "       [1.0305452 ],\n",
              "       [1.0277761 ],\n",
              "       [1.0312711 ],\n",
              "       [1.0310388 ],\n",
              "       [1.0201079 ],\n",
              "       [1.0263438 ],\n",
              "       [1.0285879 ],\n",
              "       [1.0265971 ],\n",
              "       [1.0150157 ],\n",
              "       [1.0266474 ],\n",
              "       [1.0312916 ],\n",
              "       [1.0301574 ],\n",
              "       [1.0275267 ],\n",
              "       [1.0178384 ],\n",
              "       [1.0300832 ],\n",
              "       [1.0303078 ],\n",
              "       [1.0314432 ],\n",
              "       [1.028623  ],\n",
              "       [1.0280126 ],\n",
              "       [1.0287238 ],\n",
              "       [1.0285937 ],\n",
              "       [1.0318505 ],\n",
              "       [1.0279561 ],\n",
              "       [1.0274681 ],\n",
              "       [1.0206188 ],\n",
              "       [1.0302196 ],\n",
              "       [1.0202646 ],\n",
              "       [1.0297905 ],\n",
              "       [1.027593  ],\n",
              "       [1.0168465 ],\n",
              "       [1.0290617 ],\n",
              "       [1.0312816 ],\n",
              "       [1.0299019 ],\n",
              "       [1.0310535 ],\n",
              "       [1.029756  ],\n",
              "       [1.0192157 ],\n",
              "       [1.0319885 ],\n",
              "       [1.0303797 ],\n",
              "       [1.0272577 ],\n",
              "       [1.0319515 ],\n",
              "       [1.0321321 ],\n",
              "       [1.0215594 ],\n",
              "       [1.0289075 ],\n",
              "       [1.0275347 ],\n",
              "       [1.0312649 ],\n",
              "       [1.0263635 ],\n",
              "       [1.0319825 ],\n",
              "       [1.0274695 ],\n",
              "       [1.0291528 ],\n",
              "       [1.0319244 ],\n",
              "       [1.0155965 ],\n",
              "       [1.0282698 ],\n",
              "       [1.0217135 ],\n",
              "       [1.0151266 ],\n",
              "       [1.0304408 ],\n",
              "       [1.0301173 ],\n",
              "       [1.0184731 ],\n",
              "       [1.0303051 ],\n",
              "       [1.0284603 ],\n",
              "       [1.0101889 ],\n",
              "       [1.0302755 ],\n",
              "       [1.0276686 ],\n",
              "       [1.0259874 ],\n",
              "       [1.0246965 ],\n",
              "       [1.0284044 ],\n",
              "       [1.0241351 ],\n",
              "       [1.0276998 ],\n",
              "       [1.0290097 ],\n",
              "       [1.0258882 ],\n",
              "       [1.0277877 ],\n",
              "       [1.0312483 ],\n",
              "       [1.0342419 ],\n",
              "       [1.015977  ],\n",
              "       [1.0329858 ],\n",
              "       [1.0303715 ],\n",
              "       [1.0255508 ],\n",
              "       [1.0282662 ],\n",
              "       [1.0304635 ],\n",
              "       [1.027701  ],\n",
              "       [1.0268375 ],\n",
              "       [1.0330137 ],\n",
              "       [1.0231808 ],\n",
              "       [1.0263093 ],\n",
              "       [1.0306808 ],\n",
              "       [1.0295727 ],\n",
              "       [0.98199844],\n",
              "       [1.0227479 ],\n",
              "       [1.0292226 ],\n",
              "       [1.0315548 ],\n",
              "       [1.0264195 ],\n",
              "       [1.0239968 ],\n",
              "       [1.0321511 ],\n",
              "       [1.0318621 ],\n",
              "       [1.0276059 ],\n",
              "       [1.0259012 ],\n",
              "       [1.0275028 ],\n",
              "       [1.0294067 ],\n",
              "       [1.0258733 ],\n",
              "       [1.0121845 ],\n",
              "       [0.97046894],\n",
              "       [1.0294174 ],\n",
              "       [1.0205696 ],\n",
              "       [1.0271686 ],\n",
              "       [1.0261713 ],\n",
              "       [1.0292293 ],\n",
              "       [1.0287277 ],\n",
              "       [1.0295044 ],\n",
              "       [1.0290862 ],\n",
              "       [1.02761   ],\n",
              "       [1.0138156 ],\n",
              "       [1.0304319 ],\n",
              "       [1.028434  ],\n",
              "       [1.0230373 ],\n",
              "       [1.0276742 ],\n",
              "       [1.0327187 ],\n",
              "       [1.0333797 ],\n",
              "       [1.0334476 ],\n",
              "       [1.0256616 ],\n",
              "       [1.0306681 ],\n",
              "       [1.0226839 ],\n",
              "       [1.0246991 ],\n",
              "       [1.0222728 ],\n",
              "       [1.0311987 ],\n",
              "       [1.0291649 ],\n",
              "       [1.0290667 ],\n",
              "       [1.0302622 ],\n",
              "       [1.0272486 ],\n",
              "       [1.0247515 ],\n",
              "       [1.02944   ],\n",
              "       [1.0298407 ],\n",
              "       [1.0253501 ],\n",
              "       [1.0122352 ],\n",
              "       [1.0298159 ],\n",
              "       [1.0265044 ],\n",
              "       [1.0298083 ],\n",
              "       [1.0257595 ],\n",
              "       [1.0264381 ],\n",
              "       [1.0268997 ],\n",
              "       [1.0310038 ],\n",
              "       [1.0257397 ],\n",
              "       [1.0250876 ],\n",
              "       [1.0321202 ],\n",
              "       [1.0301217 ],\n",
              "       [1.0269705 ],\n",
              "       [1.0311217 ],\n",
              "       [1.0314163 ],\n",
              "       [1.0278693 ],\n",
              "       [1.0290874 ],\n",
              "       [1.0293645 ],\n",
              "       [1.0324751 ],\n",
              "       [1.0268751 ],\n",
              "       [1.0295004 ],\n",
              "       [0.9923043 ],\n",
              "       [1.0319749 ],\n",
              "       [1.0283844 ],\n",
              "       [1.029037  ],\n",
              "       [1.0126898 ],\n",
              "       [1.0306253 ],\n",
              "       [1.0295221 ],\n",
              "       [1.0228095 ],\n",
              "       [1.0347573 ],\n",
              "       [1.0264965 ],\n",
              "       [1.0286156 ],\n",
              "       [1.0198492 ],\n",
              "       [1.0227938 ],\n",
              "       [1.029637  ],\n",
              "       [1.0280923 ],\n",
              "       [1.0293605 ],\n",
              "       [1.025749  ],\n",
              "       [1.0180831 ],\n",
              "       [1.0279933 ],\n",
              "       [1.0174516 ],\n",
              "       [1.0299248 ],\n",
              "       [1.0264697 ],\n",
              "       [1.0305392 ],\n",
              "       [1.0285064 ],\n",
              "       [1.0252639 ],\n",
              "       [1.0228281 ],\n",
              "       [0.9961649 ],\n",
              "       [1.0286539 ],\n",
              "       [1.02819   ],\n",
              "       [1.0301763 ],\n",
              "       [1.0224999 ],\n",
              "       [1.0206571 ],\n",
              "       [1.0281467 ],\n",
              "       [1.0266316 ],\n",
              "       [1.0284809 ],\n",
              "       [1.0243236 ],\n",
              "       [1.0247335 ],\n",
              "       [1.0281943 ],\n",
              "       [1.0133771 ],\n",
              "       [1.0318247 ],\n",
              "       [1.0359931 ],\n",
              "       [1.017283  ],\n",
              "       [1.027932  ],\n",
              "       [1.0315148 ],\n",
              "       [1.0311141 ],\n",
              "       [1.0280367 ],\n",
              "       [0.989426  ],\n",
              "       [1.0285218 ],\n",
              "       [1.026462  ],\n",
              "       [1.0277826 ],\n",
              "       [1.0313472 ],\n",
              "       [1.0278677 ],\n",
              "       [1.0322754 ],\n",
              "       [1.0248952 ],\n",
              "       [1.0265466 ],\n",
              "       [1.0272294 ],\n",
              "       [1.0337719 ],\n",
              "       [1.0204129 ],\n",
              "       [1.0325351 ],\n",
              "       [1.0257006 ],\n",
              "       [1.0296695 ],\n",
              "       [1.0296704 ],\n",
              "       [1.034747  ],\n",
              "       [1.0273241 ],\n",
              "       [1.0253695 ],\n",
              "       [1.0299096 ],\n",
              "       [1.029703  ],\n",
              "       [1.0316433 ],\n",
              "       [1.0300413 ],\n",
              "       [1.0306205 ],\n",
              "       [1.0183271 ],\n",
              "       [1.0316302 ],\n",
              "       [1.0254238 ],\n",
              "       [1.0310661 ],\n",
              "       [1.0210408 ],\n",
              "       [1.0268183 ],\n",
              "       [1.0272242 ],\n",
              "       [1.0201888 ],\n",
              "       [1.0226436 ],\n",
              "       [1.0265821 ],\n",
              "       [1.0304705 ],\n",
              "       [1.0219871 ],\n",
              "       [1.0325129 ],\n",
              "       [1.0292497 ],\n",
              "       [1.0229243 ],\n",
              "       [1.0270408 ],\n",
              "       [1.029826  ],\n",
              "       [1.0213648 ],\n",
              "       [1.0326825 ],\n",
              "       [1.0263963 ],\n",
              "       [1.0031034 ],\n",
              "       [1.0239764 ],\n",
              "       [1.0281186 ],\n",
              "       [1.0313569 ],\n",
              "       [1.0146388 ],\n",
              "       [1.0232651 ],\n",
              "       [1.0316347 ],\n",
              "       [1.0313298 ],\n",
              "       [1.025362  ],\n",
              "       [1.0262141 ],\n",
              "       [1.0211594 ],\n",
              "       [1.0269333 ],\n",
              "       [1.0299903 ],\n",
              "       [1.0303566 ],\n",
              "       [0.994142  ],\n",
              "       [1.0328664 ],\n",
              "       [1.0089223 ],\n",
              "       [1.0308114 ],\n",
              "       [1.0235616 ],\n",
              "       [1.0284432 ],\n",
              "       [1.0082514 ],\n",
              "       [1.0294806 ],\n",
              "       [1.021134  ],\n",
              "       [1.0212334 ],\n",
              "       [1.031139  ],\n",
              "       [1.0252868 ],\n",
              "       [1.0245769 ],\n",
              "       [1.0148828 ],\n",
              "       [1.029917  ],\n",
              "       [1.0250393 ],\n",
              "       [1.0281668 ],\n",
              "       [1.0232006 ],\n",
              "       [1.0297953 ],\n",
              "       [1.0332819 ],\n",
              "       [1.022403  ],\n",
              "       [1.0346571 ],\n",
              "       [1.032521  ],\n",
              "       [1.0286194 ],\n",
              "       [1.0313617 ],\n",
              "       [1.0112306 ],\n",
              "       [1.0297868 ],\n",
              "       [1.0286292 ],\n",
              "       [1.0305921 ],\n",
              "       [1.0280248 ],\n",
              "       [1.0269566 ],\n",
              "       [1.0273563 ],\n",
              "       [1.0196853 ],\n",
              "       [1.0326172 ],\n",
              "       [1.0097827 ],\n",
              "       [1.0244191 ],\n",
              "       [1.032837  ],\n",
              "       [1.0306835 ],\n",
              "       [1.0284792 ],\n",
              "       [1.031442  ],\n",
              "       [1.0282444 ],\n",
              "       [1.0254947 ],\n",
              "       [1.030293  ],\n",
              "       [1.0263791 ],\n",
              "       [1.019448  ],\n",
              "       [1.0282236 ],\n",
              "       [1.0288436 ],\n",
              "       [1.0324868 ],\n",
              "       [1.0238512 ],\n",
              "       [1.0154834 ],\n",
              "       [1.0275414 ],\n",
              "       [1.0275284 ],\n",
              "       [1.033337  ],\n",
              "       [1.0317711 ],\n",
              "       [1.0296131 ],\n",
              "       [1.0299693 ],\n",
              "       [1.0322529 ],\n",
              "       [1.0305257 ],\n",
              "       [1.029333  ],\n",
              "       [1.0094098 ],\n",
              "       [1.0122267 ],\n",
              "       [1.0175303 ],\n",
              "       [1.030439  ],\n",
              "       [1.0314426 ],\n",
              "       [1.0322902 ],\n",
              "       [1.0228431 ],\n",
              "       [1.0207454 ],\n",
              "       [1.0335877 ],\n",
              "       [1.0271903 ],\n",
              "       [1.0301731 ],\n",
              "       [1.0290331 ],\n",
              "       [1.0298091 ],\n",
              "       [1.0315892 ],\n",
              "       [1.0254765 ],\n",
              "       [1.031358  ],\n",
              "       [1.0320872 ],\n",
              "       [1.0122721 ],\n",
              "       [1.0335674 ],\n",
              "       [1.0306385 ],\n",
              "       [1.0313039 ],\n",
              "       [1.0264462 ],\n",
              "       [1.0282537 ],\n",
              "       [1.008227  ],\n",
              "       [1.0048571 ],\n",
              "       [1.0275372 ],\n",
              "       [1.0069113 ],\n",
              "       [1.0303353 ],\n",
              "       [1.0332971 ],\n",
              "       [1.0298156 ],\n",
              "       [1.0257683 ],\n",
              "       [1.0264779 ],\n",
              "       [1.0304427 ],\n",
              "       [1.0293611 ],\n",
              "       [1.0247139 ],\n",
              "       [1.0312083 ],\n",
              "       [1.0289065 ],\n",
              "       [1.032685  ],\n",
              "       [1.0269926 ],\n",
              "       [1.0307769 ],\n",
              "       [1.0302023 ],\n",
              "       [1.0289425 ],\n",
              "       [1.028236  ],\n",
              "       [1.0281951 ],\n",
              "       [1.0192415 ],\n",
              "       [1.0318531 ],\n",
              "       [1.0282766 ],\n",
              "       [1.029327  ],\n",
              "       [1.0296899 ],\n",
              "       [1.026074  ],\n",
              "       [1.0121582 ],\n",
              "       [1.0319421 ],\n",
              "       [1.0280195 ],\n",
              "       [1.0244147 ],\n",
              "       [1.0044808 ],\n",
              "       [1.0307363 ],\n",
              "       [1.025909  ],\n",
              "       [1.0274099 ],\n",
              "       [1.025263  ],\n",
              "       [1.0354078 ],\n",
              "       [1.0261912 ],\n",
              "       [1.0335447 ],\n",
              "       [1.0238388 ],\n",
              "       [1.0288383 ],\n",
              "       [1.0316133 ],\n",
              "       [1.0290701 ],\n",
              "       [1.029932  ],\n",
              "       [1.031458  ],\n",
              "       [1.0260482 ],\n",
              "       [1.0324765 ],\n",
              "       [1.0306123 ],\n",
              "       [1.0286313 ],\n",
              "       [1.0336224 ],\n",
              "       [1.0327863 ],\n",
              "       [1.0255405 ],\n",
              "       [1.030004  ],\n",
              "       [1.0161022 ],\n",
              "       [1.0292246 ],\n",
              "       [1.0296229 ],\n",
              "       [1.0324155 ],\n",
              "       [1.032658  ],\n",
              "       [1.0301663 ],\n",
              "       [1.0292524 ],\n",
              "       [1.0319656 ],\n",
              "       [1.0251834 ],\n",
              "       [1.0321478 ],\n",
              "       [1.0263356 ],\n",
              "       [1.030135  ],\n",
              "       [1.0282131 ],\n",
              "       [1.0230476 ],\n",
              "       [1.0308532 ],\n",
              "       [1.0305125 ],\n",
              "       [1.0305226 ],\n",
              "       [1.0340186 ],\n",
              "       [1.0108941 ],\n",
              "       [1.0306126 ],\n",
              "       [1.0304635 ],\n",
              "       [1.0291265 ],\n",
              "       [1.0312737 ],\n",
              "       [1.0295204 ],\n",
              "       [1.0296495 ],\n",
              "       [1.0236664 ],\n",
              "       [1.0224234 ],\n",
              "       [1.0263534 ],\n",
              "       [1.0296882 ],\n",
              "       [1.0297208 ],\n",
              "       [1.0276483 ],\n",
              "       [1.0283624 ],\n",
              "       [1.0328008 ],\n",
              "       [1.0274523 ],\n",
              "       [1.0318531 ],\n",
              "       [1.0273323 ],\n",
              "       [1.0224447 ],\n",
              "       [1.0279566 ],\n",
              "       [1.0296193 ],\n",
              "       [1.029207  ],\n",
              "       [1.0287133 ],\n",
              "       [1.0280356 ],\n",
              "       [1.023154  ],\n",
              "       [1.0332359 ],\n",
              "       [1.0255113 ],\n",
              "       [1.0294441 ],\n",
              "       [1.0309745 ],\n",
              "       [1.0362072 ],\n",
              "       [1.029467  ],\n",
              "       [1.0316296 ],\n",
              "       [1.0164005 ],\n",
              "       [1.0278239 ],\n",
              "       [1.0288657 ],\n",
              "       [1.0258454 ],\n",
              "       [1.033429  ],\n",
              "       [1.026698  ],\n",
              "       [1.0205638 ],\n",
              "       [1.0266052 ],\n",
              "       [1.026378  ],\n",
              "       [1.0309039 ],\n",
              "       [1.0281233 ],\n",
              "       [1.0264302 ],\n",
              "       [1.0194631 ],\n",
              "       [1.0323759 ],\n",
              "       [1.0276607 ],\n",
              "       [1.0302035 ],\n",
              "       [1.0290674 ],\n",
              "       [1.0287071 ],\n",
              "       [1.0212548 ],\n",
              "       [1.0300423 ],\n",
              "       [1.031204  ],\n",
              "       [1.0267967 ],\n",
              "       [1.0279922 ],\n",
              "       [1.0281514 ],\n",
              "       [1.0328703 ],\n",
              "       [1.0250897 ],\n",
              "       [1.0274504 ],\n",
              "       [1.0281554 ],\n",
              "       [1.0277959 ],\n",
              "       [1.0257436 ],\n",
              "       [1.0242995 ],\n",
              "       [1.0296702 ],\n",
              "       [1.01877   ],\n",
              "       [1.0264862 ],\n",
              "       [1.0258013 ],\n",
              "       [1.0305529 ],\n",
              "       [1.0280519 ],\n",
              "       [1.0249139 ],\n",
              "       [1.0286349 ],\n",
              "       [1.0302622 ],\n",
              "       [1.0214707 ],\n",
              "       [0.9975448 ],\n",
              "       [1.030132  ],\n",
              "       [1.0280613 ],\n",
              "       [1.0304121 ],\n",
              "       [1.0298233 ],\n",
              "       [1.0204172 ],\n",
              "       [1.0267425 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDoFdh3PaeQx"
      },
      "source": [
        "predicted_humor_rating = predicted_humor_rating.flatten()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ycEe2EGadPP",
        "outputId": "19e3d18c-986b-44a0-c5d2-6efb27458cec"
      },
      "source": [
        "predicted_humor_rating"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.0267284 , 1.0285598 , 1.0281565 , 1.0271419 , 1.0281172 ,\n",
              "       1.0278009 , 1.0239993 , 1.0274472 , 1.0187553 , 1.0255113 ,\n",
              "       1.029445  , 0.95011586, 1.0276228 , 1.0010127 , 1.0255418 ,\n",
              "       1.0312151 , 1.0271887 , 1.0298283 , 1.0326444 , 1.0287262 ,\n",
              "       1.0263591 , 1.0302538 , 1.0322424 , 1.0306795 , 1.0319101 ,\n",
              "       1.0275098 , 1.0270218 , 1.0322769 , 1.031878  , 1.0276121 ,\n",
              "       1.0322683 , 1.0297045 , 1.0322543 , 1.0293673 , 1.0324184 ,\n",
              "       1.0259067 , 1.0287927 , 1.0318953 , 1.0231292 , 1.0222936 ,\n",
              "       1.013496  , 1.0252734 , 1.0298206 , 1.0305101 , 1.0282704 ,\n",
              "       1.0299212 , 1.0318307 , 1.027678  , 1.0223204 , 1.0262834 ,\n",
              "       1.0315074 , 0.99708533, 1.0252414 , 1.0199237 , 1.027121  ,\n",
              "       1.0296991 , 1.0317042 , 1.0321709 , 1.0331868 , 1.0296189 ,\n",
              "       1.0272182 , 1.0249397 , 1.026282  , 1.0267897 , 1.027406  ,\n",
              "       1.0303142 , 1.0116384 , 1.0240238 , 1.0313774 , 1.0291632 ,\n",
              "       1.0307662 , 1.0309094 , 1.0242192 , 1.0318857 , 1.0289208 ,\n",
              "       1.0331874 , 1.0272065 , 1.0237353 , 1.0302877 , 1.0167003 ,\n",
              "       1.0263833 , 1.0310789 , 1.0292419 , 1.0235949 , 1.0309695 ,\n",
              "       1.0219184 , 1.0317646 , 1.0335078 , 1.0290409 , 1.0310551 ,\n",
              "       1.0237206 , 1.0271657 , 1.0283388 , 1.0176961 , 1.0188355 ,\n",
              "       1.0292913 , 1.030272  , 1.0336531 , 1.0292733 , 1.0208837 ,\n",
              "       1.0312244 , 1.0160553 , 1.0259196 , 1.0191928 , 1.027419  ,\n",
              "       1.0257195 , 1.0264622 , 1.0277934 , 1.0326469 , 1.0258994 ,\n",
              "       1.0296826 , 1.0191875 , 1.0284787 , 1.0282818 , 1.0254894 ,\n",
              "       1.0185044 , 1.0213605 , 1.022619  , 1.0262978 , 1.0274287 ,\n",
              "       1.029668  , 1.0265496 , 1.0291423 , 1.0305947 , 1.0333071 ,\n",
              "       1.0261897 , 1.0238127 , 1.0317675 , 1.0271993 , 1.0274245 ,\n",
              "       1.0319499 , 1.0223237 , 1.0302368 , 1.0175748 , 1.0210283 ,\n",
              "       1.034192  , 1.0152112 , 1.0284687 , 1.031545  , 1.031821  ,\n",
              "       1.0312549 , 1.029635  , 1.0318279 , 1.0274118 , 1.0309213 ,\n",
              "       1.015344  , 1.02838   , 1.0286465 , 1.0287071 , 1.0279241 ,\n",
              "       1.0299572 , 1.0293242 , 1.0293188 , 1.0310032 , 1.0308247 ,\n",
              "       1.0336488 , 1.0293585 , 1.0057672 , 1.0101604 , 1.0302612 ,\n",
              "       1.0264429 , 1.0305525 , 1.0272251 , 1.0294732 , 1.0295415 ,\n",
              "       1.0273689 , 1.0251772 , 1.0297054 , 1.0261072 , 1.0157075 ,\n",
              "       1.0224384 , 1.0304042 , 1.0129069 , 1.0258945 , 1.0138366 ,\n",
              "       1.0327076 , 1.0134283 , 1.0282997 , 1.0340801 , 1.0191077 ,\n",
              "       1.0218039 , 1.0317715 , 1.025211  , 1.0297685 , 1.0328379 ,\n",
              "       1.0156094 , 1.0209335 , 1.031908  , 1.022376  , 1.0273384 ,\n",
              "       1.024337  , 1.0250936 , 1.0303401 , 1.0288388 , 1.0272409 ,\n",
              "       1.0249258 , 1.0280063 , 1.0251065 , 1.0011442 , 1.0306798 ,\n",
              "       1.0237912 , 1.0292703 , 1.028055  , 1.0196432 , 1.0314205 ,\n",
              "       1.0191528 , 1.0147693 , 1.0203066 , 1.0309054 , 1.0219328 ,\n",
              "       1.0300246 , 1.0261781 , 1.026636  , 1.0317302 , 1.0323502 ,\n",
              "       1.0291106 , 1.0270919 , 1.0298854 , 1.0352558 , 1.0308143 ,\n",
              "       1.0284506 , 1.0218245 , 1.0265557 , 1.027002  , 1.0342039 ,\n",
              "       1.0249988 , 1.0090202 , 1.0259275 , 1.0305465 , 1.0278313 ,\n",
              "       1.0268675 , 1.0153433 , 1.0249782 , 1.0279514 , 1.0266169 ,\n",
              "       1.0287672 , 1.0221322 , 1.0344068 , 1.0217744 , 1.0281166 ,\n",
              "       1.0272948 , 1.02577   , 1.0316781 , 1.0285898 , 1.0299628 ,\n",
              "       1.0300233 , 0.9962118 , 1.0227708 , 1.025299  , 1.0293025 ,\n",
              "       1.0261892 , 1.0262883 , 1.0264237 , 1.0086071 , 0.9984103 ,\n",
              "       1.0210859 , 1.0148777 , 1.0263913 , 1.0091244 , 1.0313711 ,\n",
              "       1.035366  , 1.0285306 , 1.0259073 , 1.0322387 , 1.025464  ,\n",
              "       1.0315406 , 1.0300916 , 1.0215405 , 1.029529  , 1.0068079 ,\n",
              "       1.0263156 , 1.0315623 , 1.0237306 , 1.024026  , 1.0241264 ,\n",
              "       1.0175399 , 1.0315841 , 1.0283734 , 1.0274854 , 1.0264837 ,\n",
              "       1.0284401 , 1.0214417 , 1.0348984 , 1.0072839 , 1.0203964 ,\n",
              "       1.0259727 , 1.029371  , 1.030254  , 1.029029  , 1.0203665 ,\n",
              "       1.0268781 , 1.0304271 , 1.0284415 , 1.0324663 , 1.0207173 ,\n",
              "       1.0228559 , 1.02787   , 1.03028   , 1.0268352 , 1.0308269 ,\n",
              "       1.0277786 , 1.0323948 , 1.0324026 , 1.0277747 , 1.0280074 ,\n",
              "       1.0325245 , 1.018649  , 1.0267885 , 1.0287932 , 1.0300244 ,\n",
              "       1.0300361 , 1.0266782 , 1.0282016 , 1.0298547 , 1.0219337 ,\n",
              "       1.0259014 , 1.0193499 , 1.0315858 , 1.0298331 , 1.0217919 ,\n",
              "       1.0310916 , 1.0262699 , 1.0161645 , 1.0250257 , 1.0293291 ,\n",
              "       1.0292645 , 1.0292625 , 1.0281934 , 1.0227523 , 1.0291327 ,\n",
              "       1.0235852 , 1.0306102 , 1.0270365 , 0.98888165, 1.0265228 ,\n",
              "       1.0194199 , 1.0274576 , 1.031786  , 1.031007  , 1.0290749 ,\n",
              "       1.0226066 , 1.0183758 , 1.0262166 , 1.0287609 , 1.0291473 ,\n",
              "       1.0294739 , 1.0328971 , 1.0302942 , 1.0280155 , 1.025103  ,\n",
              "       1.0221776 , 1.024587  , 1.0227413 , 1.0294704 , 1.0284096 ,\n",
              "       1.0333697 , 1.030592  , 1.0285581 , 1.0044022 , 1.0298921 ,\n",
              "       1.0265005 , 1.030961  , 1.031427  , 1.018051  , 1.0282223 ,\n",
              "       1.021002  , 1.0263088 , 1.0321074 , 1.0249541 , 1.031108  ,\n",
              "       1.0300062 , 1.0101715 , 1.0239894 , 1.0269891 , 1.0272514 ,\n",
              "       1.0241921 , 0.998407  , 1.0288501 , 1.0339406 , 1.028063  ,\n",
              "       1.0324308 , 1.0239627 , 1.0272397 , 1.0270606 , 1.0231897 ,\n",
              "       1.0264387 , 1.030648  , 1.0335191 , 1.0309366 , 1.0297953 ,\n",
              "       1.0335331 , 1.0266091 , 1.0233753 , 1.0269784 , 1.0315462 ,\n",
              "       1.027817  , 1.0294276 , 1.0301683 , 1.0297348 , 1.0298091 ,\n",
              "       1.0269395 , 1.0303289 , 1.0284574 , 1.0295081 , 1.0184743 ,\n",
              "       1.027251  , 1.0260748 , 1.0295221 , 1.0309978 , 1.0298575 ,\n",
              "       1.0210345 , 1.025407  , 1.0267245 , 1.0310887 , 1.0302995 ,\n",
              "       1.0307467 , 1.0222785 , 1.0314561 , 1.0296018 , 1.0272635 ,\n",
              "       1.0289074 , 1.0289973 , 1.0246552 , 1.0272218 , 1.031696  ,\n",
              "       1.0250758 , 1.0314642 , 1.0276309 , 1.0305297 , 1.029056  ,\n",
              "       1.0294656 , 1.0266725 , 1.0279579 , 1.0312953 , 1.0180575 ,\n",
              "       1.0288292 , 1.0312349 , 1.0114758 , 1.0266346 , 1.0283052 ,\n",
              "       1.031557  , 1.020948  , 1.0311247 , 1.0290736 , 1.0232052 ,\n",
              "       1.0306503 , 1.0098855 , 1.0278487 , 1.0281236 , 1.0266956 ,\n",
              "       1.0265306 , 1.0305763 , 1.0287325 , 1.0274323 , 1.029938  ,\n",
              "       1.0307858 , 1.0265237 , 1.0334308 , 1.0312315 , 1.0306581 ,\n",
              "       1.0071824 , 1.0314997 , 1.0187008 , 1.0154933 , 1.0291547 ,\n",
              "       1.019594  , 1.0298744 , 1.0288154 , 1.031515  , 1.0260781 ,\n",
              "       1.0286995 , 1.028255  , 1.0289017 , 1.0306    , 1.004952  ,\n",
              "       1.02481   , 1.0278845 , 1.0278872 , 1.022356  , 1.0316905 ,\n",
              "       1.0279461 , 1.0288258 , 1.0316257 , 1.0205742 , 1.0135862 ,\n",
              "       1.0288187 , 1.0284795 , 1.0279931 , 1.0250303 , 1.0243636 ,\n",
              "       1.0270859 , 1.0321753 , 1.0254755 , 1.0337876 , 1.0280594 ,\n",
              "       1.0316397 , 1.0195276 , 1.0266732 , 1.0292717 , 1.0219438 ,\n",
              "       1.0310403 , 1.0300245 , 1.0259571 , 1.0297232 , 1.0130291 ,\n",
              "       1.0278529 , 1.0161908 , 1.0286053 , 1.0296632 , 1.0257707 ,\n",
              "       1.0314767 , 1.0305452 , 1.0277761 , 1.0312711 , 1.0310388 ,\n",
              "       1.0201079 , 1.0263438 , 1.0285879 , 1.0265971 , 1.0150157 ,\n",
              "       1.0266474 , 1.0312916 , 1.0301574 , 1.0275267 , 1.0178384 ,\n",
              "       1.0300832 , 1.0303078 , 1.0314432 , 1.028623  , 1.0280126 ,\n",
              "       1.0287238 , 1.0285937 , 1.0318505 , 1.0279561 , 1.0274681 ,\n",
              "       1.0206188 , 1.0302196 , 1.0202646 , 1.0297905 , 1.027593  ,\n",
              "       1.0168465 , 1.0290617 , 1.0312816 , 1.0299019 , 1.0310535 ,\n",
              "       1.029756  , 1.0192157 , 1.0319885 , 1.0303797 , 1.0272577 ,\n",
              "       1.0319515 , 1.0321321 , 1.0215594 , 1.0289075 , 1.0275347 ,\n",
              "       1.0312649 , 1.0263635 , 1.0319825 , 1.0274695 , 1.0291528 ,\n",
              "       1.0319244 , 1.0155965 , 1.0282698 , 1.0217135 , 1.0151266 ,\n",
              "       1.0304408 , 1.0301173 , 1.0184731 , 1.0303051 , 1.0284603 ,\n",
              "       1.0101889 , 1.0302755 , 1.0276686 , 1.0259874 , 1.0246965 ,\n",
              "       1.0284044 , 1.0241351 , 1.0276998 , 1.0290097 , 1.0258882 ,\n",
              "       1.0277877 , 1.0312483 , 1.0342419 , 1.015977  , 1.0329858 ,\n",
              "       1.0303715 , 1.0255508 , 1.0282662 , 1.0304635 , 1.027701  ,\n",
              "       1.0268375 , 1.0330137 , 1.0231808 , 1.0263093 , 1.0306808 ,\n",
              "       1.0295727 , 0.98199844, 1.0227479 , 1.0292226 , 1.0315548 ,\n",
              "       1.0264195 , 1.0239968 , 1.0321511 , 1.0318621 , 1.0276059 ,\n",
              "       1.0259012 , 1.0275028 , 1.0294067 , 1.0258733 , 1.0121845 ,\n",
              "       0.97046894, 1.0294174 , 1.0205696 , 1.0271686 , 1.0261713 ,\n",
              "       1.0292293 , 1.0287277 , 1.0295044 , 1.0290862 , 1.02761   ,\n",
              "       1.0138156 , 1.0304319 , 1.028434  , 1.0230373 , 1.0276742 ,\n",
              "       1.0327187 , 1.0333797 , 1.0334476 , 1.0256616 , 1.0306681 ,\n",
              "       1.0226839 , 1.0246991 , 1.0222728 , 1.0311987 , 1.0291649 ,\n",
              "       1.0290667 , 1.0302622 , 1.0272486 , 1.0247515 , 1.02944   ,\n",
              "       1.0298407 , 1.0253501 , 1.0122352 , 1.0298159 , 1.0265044 ,\n",
              "       1.0298083 , 1.0257595 , 1.0264381 , 1.0268997 , 1.0310038 ,\n",
              "       1.0257397 , 1.0250876 , 1.0321202 , 1.0301217 , 1.0269705 ,\n",
              "       1.0311217 , 1.0314163 , 1.0278693 , 1.0290874 , 1.0293645 ,\n",
              "       1.0324751 , 1.0268751 , 1.0295004 , 0.9923043 , 1.0319749 ,\n",
              "       1.0283844 , 1.029037  , 1.0126898 , 1.0306253 , 1.0295221 ,\n",
              "       1.0228095 , 1.0347573 , 1.0264965 , 1.0286156 , 1.0198492 ,\n",
              "       1.0227938 , 1.029637  , 1.0280923 , 1.0293605 , 1.025749  ,\n",
              "       1.0180831 , 1.0279933 , 1.0174516 , 1.0299248 , 1.0264697 ,\n",
              "       1.0305392 , 1.0285064 , 1.0252639 , 1.0228281 , 0.9961649 ,\n",
              "       1.0286539 , 1.02819   , 1.0301763 , 1.0224999 , 1.0206571 ,\n",
              "       1.0281467 , 1.0266316 , 1.0284809 , 1.0243236 , 1.0247335 ,\n",
              "       1.0281943 , 1.0133771 , 1.0318247 , 1.0359931 , 1.017283  ,\n",
              "       1.027932  , 1.0315148 , 1.0311141 , 1.0280367 , 0.989426  ,\n",
              "       1.0285218 , 1.026462  , 1.0277826 , 1.0313472 , 1.0278677 ,\n",
              "       1.0322754 , 1.0248952 , 1.0265466 , 1.0272294 , 1.0337719 ,\n",
              "       1.0204129 , 1.0325351 , 1.0257006 , 1.0296695 , 1.0296704 ,\n",
              "       1.034747  , 1.0273241 , 1.0253695 , 1.0299096 , 1.029703  ,\n",
              "       1.0316433 , 1.0300413 , 1.0306205 , 1.0183271 , 1.0316302 ,\n",
              "       1.0254238 , 1.0310661 , 1.0210408 , 1.0268183 , 1.0272242 ,\n",
              "       1.0201888 , 1.0226436 , 1.0265821 , 1.0304705 , 1.0219871 ,\n",
              "       1.0325129 , 1.0292497 , 1.0229243 , 1.0270408 , 1.029826  ,\n",
              "       1.0213648 , 1.0326825 , 1.0263963 , 1.0031034 , 1.0239764 ,\n",
              "       1.0281186 , 1.0313569 , 1.0146388 , 1.0232651 , 1.0316347 ,\n",
              "       1.0313298 , 1.025362  , 1.0262141 , 1.0211594 , 1.0269333 ,\n",
              "       1.0299903 , 1.0303566 , 0.994142  , 1.0328664 , 1.0089223 ,\n",
              "       1.0308114 , 1.0235616 , 1.0284432 , 1.0082514 , 1.0294806 ,\n",
              "       1.021134  , 1.0212334 , 1.031139  , 1.0252868 , 1.0245769 ,\n",
              "       1.0148828 , 1.029917  , 1.0250393 , 1.0281668 , 1.0232006 ,\n",
              "       1.0297953 , 1.0332819 , 1.022403  , 1.0346571 , 1.032521  ,\n",
              "       1.0286194 , 1.0313617 , 1.0112306 , 1.0297868 , 1.0286292 ,\n",
              "       1.0305921 , 1.0280248 , 1.0269566 , 1.0273563 , 1.0196853 ,\n",
              "       1.0326172 , 1.0097827 , 1.0244191 , 1.032837  , 1.0306835 ,\n",
              "       1.0284792 , 1.031442  , 1.0282444 , 1.0254947 , 1.030293  ,\n",
              "       1.0263791 , 1.019448  , 1.0282236 , 1.0288436 , 1.0324868 ,\n",
              "       1.0238512 , 1.0154834 , 1.0275414 , 1.0275284 , 1.033337  ,\n",
              "       1.0317711 , 1.0296131 , 1.0299693 , 1.0322529 , 1.0305257 ,\n",
              "       1.029333  , 1.0094098 , 1.0122267 , 1.0175303 , 1.030439  ,\n",
              "       1.0314426 , 1.0322902 , 1.0228431 , 1.0207454 , 1.0335877 ,\n",
              "       1.0271903 , 1.0301731 , 1.0290331 , 1.0298091 , 1.0315892 ,\n",
              "       1.0254765 , 1.031358  , 1.0320872 , 1.0122721 , 1.0335674 ,\n",
              "       1.0306385 , 1.0313039 , 1.0264462 , 1.0282537 , 1.008227  ,\n",
              "       1.0048571 , 1.0275372 , 1.0069113 , 1.0303353 , 1.0332971 ,\n",
              "       1.0298156 , 1.0257683 , 1.0264779 , 1.0304427 , 1.0293611 ,\n",
              "       1.0247139 , 1.0312083 , 1.0289065 , 1.032685  , 1.0269926 ,\n",
              "       1.0307769 , 1.0302023 , 1.0289425 , 1.028236  , 1.0281951 ,\n",
              "       1.0192415 , 1.0318531 , 1.0282766 , 1.029327  , 1.0296899 ,\n",
              "       1.026074  , 1.0121582 , 1.0319421 , 1.0280195 , 1.0244147 ,\n",
              "       1.0044808 , 1.0307363 , 1.025909  , 1.0274099 , 1.025263  ,\n",
              "       1.0354078 , 1.0261912 , 1.0335447 , 1.0238388 , 1.0288383 ,\n",
              "       1.0316133 , 1.0290701 , 1.029932  , 1.031458  , 1.0260482 ,\n",
              "       1.0324765 , 1.0306123 , 1.0286313 , 1.0336224 , 1.0327863 ,\n",
              "       1.0255405 , 1.030004  , 1.0161022 , 1.0292246 , 1.0296229 ,\n",
              "       1.0324155 , 1.032658  , 1.0301663 , 1.0292524 , 1.0319656 ,\n",
              "       1.0251834 , 1.0321478 , 1.0263356 , 1.030135  , 1.0282131 ,\n",
              "       1.0230476 , 1.0308532 , 1.0305125 , 1.0305226 , 1.0340186 ,\n",
              "       1.0108941 , 1.0306126 , 1.0304635 , 1.0291265 , 1.0312737 ,\n",
              "       1.0295204 , 1.0296495 , 1.0236664 , 1.0224234 , 1.0263534 ,\n",
              "       1.0296882 , 1.0297208 , 1.0276483 , 1.0283624 , 1.0328008 ,\n",
              "       1.0274523 , 1.0318531 , 1.0273323 , 1.0224447 , 1.0279566 ,\n",
              "       1.0296193 , 1.029207  , 1.0287133 , 1.0280356 , 1.023154  ,\n",
              "       1.0332359 , 1.0255113 , 1.0294441 , 1.0309745 , 1.0362072 ,\n",
              "       1.029467  , 1.0316296 , 1.0164005 , 1.0278239 , 1.0288657 ,\n",
              "       1.0258454 , 1.033429  , 1.026698  , 1.0205638 , 1.0266052 ,\n",
              "       1.026378  , 1.0309039 , 1.0281233 , 1.0264302 , 1.0194631 ,\n",
              "       1.0323759 , 1.0276607 , 1.0302035 , 1.0290674 , 1.0287071 ,\n",
              "       1.0212548 , 1.0300423 , 1.031204  , 1.0267967 , 1.0279922 ,\n",
              "       1.0281514 , 1.0328703 , 1.0250897 , 1.0274504 , 1.0281554 ,\n",
              "       1.0277959 , 1.0257436 , 1.0242995 , 1.0296702 , 1.01877   ,\n",
              "       1.0264862 , 1.0258013 , 1.0305529 , 1.0280519 , 1.0249139 ,\n",
              "       1.0286349 , 1.0302622 , 1.0214707 , 0.9975448 , 1.030132  ,\n",
              "       1.0280613 , 1.0304121 , 1.0298233 , 1.0204172 , 1.0267425 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP0YfUSNcQ0-"
      },
      "source": [
        "offense_rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QV01vdWcOgW",
        "outputId": "b87dd937-d028-48ca-a82d-6a6b1d9ec3fa"
      },
      "source": [
        "X_train = df_train.text\n",
        "y_train = df_train.offense_rating\n",
        "X_test = df_test.text\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "print(\"Preparing model input ...\")\n",
        "X_train_Glove, X_test_Glove, word_index, embeddings_dict = prepare_model_input(X_train,X_test)\n",
        "print(\"Done!\")\n",
        "print(\"Building Model!\")\n",
        "model = build_bilstm(word_index, embeddings_dict, 2)\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing model input ...\n",
            "Found 7193 unique tokens.\n",
            "(5932, 500)\n",
            "Total 400000 word vectors.\n",
            "Done!\n",
            "Building Model!\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 500, 300)          2158200   \n",
            "_________________________________________________________________\n",
            "bidirectional_15 (Bidirectio (None, 500, 64)           85248     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_16 (Bidirectio (None, 500, 64)           24832     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_17 (Bidirectio (None, 500, 64)           24832     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_18 (Bidirectio (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 2,334,841\n",
            "Trainable params: 2,334,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUdi6FhpcPCd",
        "outputId": "1430c068-6789-420a-854a-27b846871ef4"
      },
      "source": [
        "history = model.fit(X_train_Glove, y_train,\n",
        "                           epochs=5,\n",
        "                           batch_size=128,\n",
        "                           verbose=1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "39/39 [==============================] - 200s 5s/step - loss: 1.3340\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 200s 5s/step - loss: 1.1137\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 200s 5s/step - loss: 0.7694\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 201s 5s/step - loss: 0.5193\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 199s 5s/step - loss: 0.4095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHr_KI1ocPcf",
        "outputId": "d99690f0-79dd-489e-bb9f-fd6936fb18df"
      },
      "source": [
        "print(\"\\n Evaluating Model ... \\n\")\n",
        "predicted_offense_rating = model.predict(X_test_Glove)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluating Model ... \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFssDqQdcPwA",
        "outputId": "4b9c8717-f0d1-4db3-d80e-032055afcdc8"
      },
      "source": [
        "predicted_offense_rating"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.0271165 ],\n",
              "       [1.896576  ],\n",
              "       [2.1201699 ],\n",
              "       [3.2450128 ],\n",
              "       [1.7613202 ],\n",
              "       [1.7344034 ],\n",
              "       [2.6720512 ],\n",
              "       [1.1171514 ],\n",
              "       [0.6002183 ],\n",
              "       [0.5154519 ],\n",
              "       [0.33436006],\n",
              "       [0.12961584],\n",
              "       [1.124236  ],\n",
              "       [0.42192784],\n",
              "       [0.7212789 ],\n",
              "       [0.2723115 ],\n",
              "       [0.37618116],\n",
              "       [2.1258643 ],\n",
              "       [0.319362  ],\n",
              "       [0.15746091],\n",
              "       [0.37909022],\n",
              "       [2.5595894 ],\n",
              "       [0.5490056 ],\n",
              "       [0.22213979],\n",
              "       [0.6257827 ],\n",
              "       [0.23107436],\n",
              "       [0.19846725],\n",
              "       [0.47175846],\n",
              "       [0.77722335],\n",
              "       [0.64708066],\n",
              "       [0.19188762],\n",
              "       [1.4412674 ],\n",
              "       [0.22845186],\n",
              "       [0.6946441 ],\n",
              "       [0.35655954],\n",
              "       [0.23574781],\n",
              "       [2.3164427 ],\n",
              "       [2.7892802 ],\n",
              "       [0.14357847],\n",
              "       [0.15241799],\n",
              "       [1.6423002 ],\n",
              "       [0.3616983 ],\n",
              "       [0.43435806],\n",
              "       [0.98469675],\n",
              "       [0.89692354],\n",
              "       [0.15364383],\n",
              "       [0.41191095],\n",
              "       [0.32432058],\n",
              "       [0.1038937 ],\n",
              "       [0.8024137 ],\n",
              "       [0.17779343],\n",
              "       [0.6845093 ],\n",
              "       [0.17933166],\n",
              "       [0.3659422 ],\n",
              "       [0.82341516],\n",
              "       [1.0088638 ],\n",
              "       [0.33626768],\n",
              "       [0.49635512],\n",
              "       [1.4815007 ],\n",
              "       [0.31727186],\n",
              "       [0.20426294],\n",
              "       [0.7184721 ],\n",
              "       [2.4581704 ],\n",
              "       [0.84858996],\n",
              "       [0.19902207],\n",
              "       [0.2223233 ],\n",
              "       [0.83179986],\n",
              "       [0.1372609 ],\n",
              "       [0.44449526],\n",
              "       [0.20384356],\n",
              "       [0.67849123],\n",
              "       [0.4172039 ],\n",
              "       [1.7779578 ],\n",
              "       [0.38052392],\n",
              "       [0.64846236],\n",
              "       [0.24002549],\n",
              "       [2.965106  ],\n",
              "       [0.21852635],\n",
              "       [0.2515579 ],\n",
              "       [0.19377418],\n",
              "       [0.2851989 ],\n",
              "       [1.7160257 ],\n",
              "       [0.4768445 ],\n",
              "       [0.505504  ],\n",
              "       [0.22690903],\n",
              "       [0.4043936 ],\n",
              "       [2.700632  ],\n",
              "       [0.19521344],\n",
              "       [0.28227547],\n",
              "       [1.5091721 ],\n",
              "       [3.2198412 ],\n",
              "       [2.362967  ],\n",
              "       [0.4485904 ],\n",
              "       [2.677055  ],\n",
              "       [0.4909415 ],\n",
              "       [0.9374242 ],\n",
              "       [0.26108634],\n",
              "       [0.71656424],\n",
              "       [3.2034059 ],\n",
              "       [1.2136708 ],\n",
              "       [0.44516003],\n",
              "       [0.22842945],\n",
              "       [0.2522289 ],\n",
              "       [0.4239993 ],\n",
              "       [0.3112078 ],\n",
              "       [1.0492024 ],\n",
              "       [0.618349  ],\n",
              "       [0.46689737],\n",
              "       [0.21531853],\n",
              "       [2.9900718 ],\n",
              "       [1.4368274 ],\n",
              "       [0.45198974],\n",
              "       [0.4683835 ],\n",
              "       [0.48953304],\n",
              "       [0.2526969 ],\n",
              "       [0.3770381 ],\n",
              "       [0.30116177],\n",
              "       [0.16823605],\n",
              "       [0.54011726],\n",
              "       [0.5908351 ],\n",
              "       [0.6287879 ],\n",
              "       [0.20103435],\n",
              "       [0.46424758],\n",
              "       [0.13980414],\n",
              "       [1.0170039 ],\n",
              "       [0.1208317 ],\n",
              "       [0.26478115],\n",
              "       [0.57108486],\n",
              "       [1.2086372 ],\n",
              "       [0.1942943 ],\n",
              "       [1.5560942 ],\n",
              "       [2.1169603 ],\n",
              "       [0.13946195],\n",
              "       [0.19190083],\n",
              "       [0.88436985],\n",
              "       [0.29908225],\n",
              "       [0.5445812 ],\n",
              "       [0.3048217 ],\n",
              "       [0.3440335 ],\n",
              "       [0.50359726],\n",
              "       [0.20936996],\n",
              "       [2.3203874 ],\n",
              "       [1.0454282 ],\n",
              "       [0.18510096],\n",
              "       [2.6209497 ],\n",
              "       [0.85112345],\n",
              "       [0.29363576],\n",
              "       [0.29016054],\n",
              "       [0.94484794],\n",
              "       [2.2091005 ],\n",
              "       [0.60926807],\n",
              "       [0.65890115],\n",
              "       [0.31633788],\n",
              "       [0.29248443],\n",
              "       [1.4420679 ],\n",
              "       [0.3988063 ],\n",
              "       [1.5563977 ],\n",
              "       [0.94197226],\n",
              "       [0.7265014 ],\n",
              "       [0.15742032],\n",
              "       [0.1920934 ],\n",
              "       [0.60265017],\n",
              "       [0.27621624],\n",
              "       [1.6643646 ],\n",
              "       [0.90581244],\n",
              "       [0.812045  ],\n",
              "       [0.3316876 ],\n",
              "       [0.22237751],\n",
              "       [2.9468207 ],\n",
              "       [2.7653909 ],\n",
              "       [0.8232232 ],\n",
              "       [1.0639004 ],\n",
              "       [0.2266482 ],\n",
              "       [0.5491061 ],\n",
              "       [0.16575256],\n",
              "       [0.7233842 ],\n",
              "       [1.6435063 ],\n",
              "       [0.43088314],\n",
              "       [0.5155402 ],\n",
              "       [0.15113777],\n",
              "       [2.0171032 ],\n",
              "       [0.4571538 ],\n",
              "       [0.17854498],\n",
              "       [0.22228646],\n",
              "       [1.5869248 ],\n",
              "       [0.88403994],\n",
              "       [0.32044277],\n",
              "       [1.0565838 ],\n",
              "       [0.5141452 ],\n",
              "       [0.24464932],\n",
              "       [0.56510127],\n",
              "       [0.24601896],\n",
              "       [0.77389073],\n",
              "       [0.95155156],\n",
              "       [0.38398048],\n",
              "       [0.32633904],\n",
              "       [0.41093495],\n",
              "       [0.34233823],\n",
              "       [0.4398754 ],\n",
              "       [0.45694503],\n",
              "       [0.5338436 ],\n",
              "       [0.26439315],\n",
              "       [1.0136153 ],\n",
              "       [0.30588797],\n",
              "       [0.338971  ],\n",
              "       [2.3116734 ],\n",
              "       [2.3738332 ],\n",
              "       [3.0181208 ],\n",
              "       [3.3189292 ],\n",
              "       [0.8708214 ],\n",
              "       [1.1557661 ],\n",
              "       [3.196076  ],\n",
              "       [0.6520543 ],\n",
              "       [2.1191773 ],\n",
              "       [0.5884388 ],\n",
              "       [0.6286407 ],\n",
              "       [0.4426485 ],\n",
              "       [0.81547046],\n",
              "       [0.33259013],\n",
              "       [0.18601993],\n",
              "       [0.31000128],\n",
              "       [2.9270802 ],\n",
              "       [0.47174132],\n",
              "       [0.24985114],\n",
              "       [0.34749156],\n",
              "       [1.0216537 ],\n",
              "       [0.18828873],\n",
              "       [2.0007799 ],\n",
              "       [0.47599384],\n",
              "       [0.21082737],\n",
              "       [2.6922054 ],\n",
              "       [3.4456172 ],\n",
              "       [2.8357024 ],\n",
              "       [1.3611253 ],\n",
              "       [0.24389592],\n",
              "       [1.1636525 ],\n",
              "       [1.1429104 ],\n",
              "       [0.8837111 ],\n",
              "       [2.9385662 ],\n",
              "       [0.44850495],\n",
              "       [2.2464647 ],\n",
              "       [0.15019926],\n",
              "       [0.62009174],\n",
              "       [0.2620964 ],\n",
              "       [1.2772306 ],\n",
              "       [0.52257866],\n",
              "       [0.77738565],\n",
              "       [1.0574967 ],\n",
              "       [0.11947341],\n",
              "       [0.2387808 ],\n",
              "       [0.22058298],\n",
              "       [0.24525148],\n",
              "       [2.6971679 ],\n",
              "       [0.22846949],\n",
              "       [0.23530723],\n",
              "       [0.3844706 ],\n",
              "       [0.18427204],\n",
              "       [0.28315866],\n",
              "       [0.31059024],\n",
              "       [0.7963013 ],\n",
              "       [0.6763817 ],\n",
              "       [0.38032725],\n",
              "       [0.21170281],\n",
              "       [0.32498732],\n",
              "       [2.931019  ],\n",
              "       [0.46051666],\n",
              "       [0.50982827],\n",
              "       [1.1008934 ],\n",
              "       [0.35798708],\n",
              "       [0.30106035],\n",
              "       [0.13091178],\n",
              "       [0.44736287],\n",
              "       [0.23391807],\n",
              "       [1.2622005 ],\n",
              "       [0.29961625],\n",
              "       [0.16312158],\n",
              "       [1.7706331 ],\n",
              "       [2.8679054 ],\n",
              "       [0.07851921],\n",
              "       [0.14355995],\n",
              "       [0.2516204 ],\n",
              "       [0.37446216],\n",
              "       [0.90643835],\n",
              "       [2.1838624 ],\n",
              "       [0.30885744],\n",
              "       [1.262173  ],\n",
              "       [1.471939  ],\n",
              "       [0.8529843 ],\n",
              "       [3.3108048 ],\n",
              "       [0.40335557],\n",
              "       [0.65889734],\n",
              "       [1.9313394 ],\n",
              "       [0.36313346],\n",
              "       [0.4514331 ],\n",
              "       [0.30700836],\n",
              "       [3.0560951 ],\n",
              "       [0.26499265],\n",
              "       [0.6887171 ],\n",
              "       [0.54498994],\n",
              "       [0.51430434],\n",
              "       [0.3074169 ],\n",
              "       [1.751155  ],\n",
              "       [1.3855118 ],\n",
              "       [0.80679077],\n",
              "       [1.3948892 ],\n",
              "       [0.6953784 ],\n",
              "       [2.193581  ],\n",
              "       [0.3634752 ],\n",
              "       [1.5497786 ],\n",
              "       [0.757398  ],\n",
              "       [0.17536235],\n",
              "       [1.4980116 ],\n",
              "       [0.67885333],\n",
              "       [0.2899495 ],\n",
              "       [0.4457927 ],\n",
              "       [0.14954205],\n",
              "       [0.9542153 ],\n",
              "       [0.28191474],\n",
              "       [0.42625758],\n",
              "       [0.39706767],\n",
              "       [0.29267693],\n",
              "       [1.9868779 ],\n",
              "       [0.1213617 ],\n",
              "       [0.6614335 ],\n",
              "       [0.45285544],\n",
              "       [0.5141548 ],\n",
              "       [0.49638832],\n",
              "       [0.315141  ],\n",
              "       [0.4953814 ],\n",
              "       [0.7396157 ],\n",
              "       [0.16157112],\n",
              "       [0.62014997],\n",
              "       [2.682142  ],\n",
              "       [0.40031448],\n",
              "       [2.903593  ],\n",
              "       [1.9192668 ],\n",
              "       [1.8227551 ],\n",
              "       [1.123481  ],\n",
              "       [0.41934124],\n",
              "       [1.4028753 ],\n",
              "       [1.0381314 ],\n",
              "       [0.49553367],\n",
              "       [0.29053822],\n",
              "       [1.609689  ],\n",
              "       [0.28598374],\n",
              "       [0.7787446 ],\n",
              "       [0.21077695],\n",
              "       [0.18491435],\n",
              "       [1.2989001 ],\n",
              "       [2.7553115 ],\n",
              "       [0.3722776 ],\n",
              "       [1.2978777 ],\n",
              "       [0.38300803],\n",
              "       [0.5501648 ],\n",
              "       [2.5374649 ],\n",
              "       [0.6002908 ],\n",
              "       [0.48659837],\n",
              "       [0.30791935],\n",
              "       [0.36524162],\n",
              "       [0.6253863 ],\n",
              "       [1.8739504 ],\n",
              "       [0.18898839],\n",
              "       [0.319759  ],\n",
              "       [0.42347047],\n",
              "       [0.13863844],\n",
              "       [0.139138  ],\n",
              "       [0.4885184 ],\n",
              "       [0.23147199],\n",
              "       [1.0323231 ],\n",
              "       [2.838278  ],\n",
              "       [1.465859  ],\n",
              "       [1.7169571 ],\n",
              "       [0.20218101],\n",
              "       [0.17506674],\n",
              "       [0.79160416],\n",
              "       [2.0129554 ],\n",
              "       [0.23820636],\n",
              "       [1.1895021 ],\n",
              "       [0.44384405],\n",
              "       [0.34214035],\n",
              "       [0.28396052],\n",
              "       [1.6166738 ],\n",
              "       [1.4842418 ],\n",
              "       [0.15395592],\n",
              "       [0.24810916],\n",
              "       [0.32417968],\n",
              "       [0.39263234],\n",
              "       [2.8972762 ],\n",
              "       [0.17178766],\n",
              "       [1.3191074 ],\n",
              "       [1.489968  ],\n",
              "       [1.3120598 ],\n",
              "       [0.32740006],\n",
              "       [0.67380416],\n",
              "       [0.33706316],\n",
              "       [0.4245316 ],\n",
              "       [0.5472423 ],\n",
              "       [0.166072  ],\n",
              "       [2.673592  ],\n",
              "       [0.4455845 ],\n",
              "       [1.404143  ],\n",
              "       [1.9622818 ],\n",
              "       [2.657781  ],\n",
              "       [3.020989  ],\n",
              "       [0.21293104],\n",
              "       [0.8569104 ],\n",
              "       [0.7188083 ],\n",
              "       [2.1550498 ],\n",
              "       [0.7914973 ],\n",
              "       [0.46535388],\n",
              "       [0.19166039],\n",
              "       [0.38533953],\n",
              "       [1.7988707 ],\n",
              "       [1.609245  ],\n",
              "       [0.6601069 ],\n",
              "       [1.8062236 ],\n",
              "       [0.26763165],\n",
              "       [0.3868189 ],\n",
              "       [2.6062553 ],\n",
              "       [0.49691775],\n",
              "       [3.0006928 ],\n",
              "       [0.21427861],\n",
              "       [0.33893207],\n",
              "       [0.48547187],\n",
              "       [0.71511596],\n",
              "       [0.20363207],\n",
              "       [0.47951147],\n",
              "       [0.19606528],\n",
              "       [0.58471185],\n",
              "       [0.2032049 ],\n",
              "       [0.2875802 ],\n",
              "       [0.22773407],\n",
              "       [1.7943202 ],\n",
              "       [0.6081048 ],\n",
              "       [0.34866485],\n",
              "       [0.24802339],\n",
              "       [3.3238623 ],\n",
              "       [1.3079907 ],\n",
              "       [2.6375833 ],\n",
              "       [0.68519163],\n",
              "       [0.7964823 ],\n",
              "       [0.22966409],\n",
              "       [0.59015906],\n",
              "       [0.823544  ],\n",
              "       [0.14549853],\n",
              "       [0.49202424],\n",
              "       [0.17183094],\n",
              "       [0.3646722 ],\n",
              "       [1.9157767 ],\n",
              "       [1.7326578 ],\n",
              "       [2.132223  ],\n",
              "       [0.35457948],\n",
              "       [0.33215097],\n",
              "       [0.18342832],\n",
              "       [2.1218452 ],\n",
              "       [0.6644008 ],\n",
              "       [1.9758407 ],\n",
              "       [1.2842206 ],\n",
              "       [0.8189064 ],\n",
              "       [0.14481582],\n",
              "       [0.57081735],\n",
              "       [0.9774926 ],\n",
              "       [0.3347932 ],\n",
              "       [0.4273176 ],\n",
              "       [0.29069722],\n",
              "       [0.37259096],\n",
              "       [0.27954984],\n",
              "       [0.30092666],\n",
              "       [0.33111128],\n",
              "       [2.2358952 ],\n",
              "       [0.7008424 ],\n",
              "       [0.30285773],\n",
              "       [0.19831711],\n",
              "       [0.3341631 ],\n",
              "       [0.63176215],\n",
              "       [0.12775092],\n",
              "       [0.16170174],\n",
              "       [0.68508387],\n",
              "       [2.1941676 ],\n",
              "       [0.29392934],\n",
              "       [1.8392037 ],\n",
              "       [0.5985247 ],\n",
              "       [1.5797747 ],\n",
              "       [0.67681193],\n",
              "       [0.27074736],\n",
              "       [0.5101922 ],\n",
              "       [3.1064258 ],\n",
              "       [1.4159106 ],\n",
              "       [0.28344205],\n",
              "       [0.4708858 ],\n",
              "       [0.18598957],\n",
              "       [0.9939339 ],\n",
              "       [0.4716154 ],\n",
              "       [0.34347844],\n",
              "       [2.2208588 ],\n",
              "       [2.5473442 ],\n",
              "       [0.6003206 ],\n",
              "       [1.3604574 ],\n",
              "       [0.18863449],\n",
              "       [2.8123121 ],\n",
              "       [0.3031968 ],\n",
              "       [0.92415816],\n",
              "       [2.7024598 ],\n",
              "       [0.31736144],\n",
              "       [1.4525307 ],\n",
              "       [1.6475747 ],\n",
              "       [0.6047802 ],\n",
              "       [2.9914474 ],\n",
              "       [0.81766814],\n",
              "       [0.25086433],\n",
              "       [0.2011062 ],\n",
              "       [1.1095632 ],\n",
              "       [0.1685859 ],\n",
              "       [0.52965486],\n",
              "       [0.31062275],\n",
              "       [0.6173116 ],\n",
              "       [0.73313373],\n",
              "       [0.3545064 ],\n",
              "       [0.2212192 ],\n",
              "       [0.47443664],\n",
              "       [0.8438908 ],\n",
              "       [0.5016353 ],\n",
              "       [0.7163888 ],\n",
              "       [0.38279757],\n",
              "       [0.32109877],\n",
              "       [1.2427822 ],\n",
              "       [0.15823773],\n",
              "       [1.4183882 ],\n",
              "       [0.5860263 ],\n",
              "       [0.2662115 ],\n",
              "       [0.668152  ],\n",
              "       [1.8394731 ],\n",
              "       [0.15958802],\n",
              "       [2.126411  ],\n",
              "       [0.85794926],\n",
              "       [0.61751056],\n",
              "       [3.1355186 ],\n",
              "       [0.34793177],\n",
              "       [0.61916417],\n",
              "       [0.22245413],\n",
              "       [3.276657  ],\n",
              "       [0.88653004],\n",
              "       [2.549078  ],\n",
              "       [0.8760294 ],\n",
              "       [0.38436416],\n",
              "       [0.34440827],\n",
              "       [2.6321049 ],\n",
              "       [0.9633766 ],\n",
              "       [0.29620174],\n",
              "       [0.24302238],\n",
              "       [0.37330687],\n",
              "       [2.4860518 ],\n",
              "       [0.568507  ],\n",
              "       [2.89194   ],\n",
              "       [0.65569603],\n",
              "       [0.1790892 ],\n",
              "       [1.195871  ],\n",
              "       [0.45701995],\n",
              "       [0.19737484],\n",
              "       [0.63830566],\n",
              "       [0.8363475 ],\n",
              "       [0.2311045 ],\n",
              "       [0.1501156 ],\n",
              "       [0.759225  ],\n",
              "       [0.31231907],\n",
              "       [0.23914392],\n",
              "       [0.35866627],\n",
              "       [1.7331831 ],\n",
              "       [2.881639  ],\n",
              "       [1.1124386 ],\n",
              "       [0.12129939],\n",
              "       [1.5478631 ],\n",
              "       [0.15716438],\n",
              "       [0.42191228],\n",
              "       [0.37905967],\n",
              "       [0.27403715],\n",
              "       [0.950551  ],\n",
              "       [0.9911299 ],\n",
              "       [0.6897536 ],\n",
              "       [0.352591  ],\n",
              "       [1.4466686 ],\n",
              "       [0.175662  ],\n",
              "       [2.5096624 ],\n",
              "       [3.0660462 ],\n",
              "       [0.65837437],\n",
              "       [0.24866691],\n",
              "       [0.20864305],\n",
              "       [0.19765168],\n",
              "       [0.22432825],\n",
              "       [0.34437504],\n",
              "       [1.018715  ],\n",
              "       [0.56330454],\n",
              "       [2.305974  ],\n",
              "       [2.3810568 ],\n",
              "       [0.71465117],\n",
              "       [1.6669612 ],\n",
              "       [0.12792176],\n",
              "       [0.30206987],\n",
              "       [1.5469536 ],\n",
              "       [3.073663  ],\n",
              "       [0.5268405 ],\n",
              "       [0.16967526],\n",
              "       [0.1866472 ],\n",
              "       [0.48601976],\n",
              "       [0.46863857],\n",
              "       [0.20020159],\n",
              "       [0.9762627 ],\n",
              "       [0.9925358 ],\n",
              "       [0.34352234],\n",
              "       [0.27383837],\n",
              "       [0.4054937 ],\n",
              "       [0.70717406],\n",
              "       [1.0406691 ],\n",
              "       [0.37070733],\n",
              "       [0.38710698],\n",
              "       [0.30575195],\n",
              "       [0.29040816],\n",
              "       [0.85210353],\n",
              "       [1.6015793 ],\n",
              "       [1.0382241 ],\n",
              "       [0.17214814],\n",
              "       [1.5303243 ],\n",
              "       [0.1650632 ],\n",
              "       [0.3154431 ],\n",
              "       [0.27868596],\n",
              "       [0.68364346],\n",
              "       [1.0561563 ],\n",
              "       [1.9263862 ],\n",
              "       [1.0239561 ],\n",
              "       [0.2604644 ],\n",
              "       [1.1703581 ],\n",
              "       [1.8516737 ],\n",
              "       [0.8904301 ],\n",
              "       [0.2811065 ],\n",
              "       [0.12931086],\n",
              "       [0.56813335],\n",
              "       [1.5639313 ],\n",
              "       [0.37413672],\n",
              "       [1.5300952 ],\n",
              "       [3.0694346 ],\n",
              "       [0.30270818],\n",
              "       [2.3252187 ],\n",
              "       [0.17110525],\n",
              "       [0.5171244 ],\n",
              "       [0.2980555 ],\n",
              "       [2.4910092 ],\n",
              "       [1.368339  ],\n",
              "       [0.45702282],\n",
              "       [2.6672356 ],\n",
              "       [1.0397052 ],\n",
              "       [0.18290974],\n",
              "       [0.25779653],\n",
              "       [2.4222078 ],\n",
              "       [0.72523534],\n",
              "       [0.21714854],\n",
              "       [0.37309092],\n",
              "       [2.2601447 ],\n",
              "       [0.35660407],\n",
              "       [0.56190145],\n",
              "       [0.28085127],\n",
              "       [2.9955034 ],\n",
              "       [2.6137323 ],\n",
              "       [0.1347381 ],\n",
              "       [0.2206693 ],\n",
              "       [0.28335255],\n",
              "       [2.1892164 ],\n",
              "       [1.2667563 ],\n",
              "       [0.53437924],\n",
              "       [1.3414953 ],\n",
              "       [0.72907686],\n",
              "       [1.2017989 ],\n",
              "       [0.71783197],\n",
              "       [0.35090402],\n",
              "       [1.982381  ],\n",
              "       [1.139278  ],\n",
              "       [0.24044955],\n",
              "       [3.1215825 ],\n",
              "       [0.623162  ],\n",
              "       [2.3626206 ],\n",
              "       [0.14969558],\n",
              "       [0.6158854 ],\n",
              "       [0.5122527 ],\n",
              "       [2.9675827 ],\n",
              "       [1.6752931 ],\n",
              "       [0.4480295 ],\n",
              "       [0.76552606],\n",
              "       [0.18142575],\n",
              "       [0.26442152],\n",
              "       [0.8182821 ],\n",
              "       [0.20726427],\n",
              "       [0.1576922 ],\n",
              "       [0.14061767],\n",
              "       [0.62672126],\n",
              "       [1.5828301 ],\n",
              "       [0.19237892],\n",
              "       [2.7400756 ],\n",
              "       [1.6413289 ],\n",
              "       [2.335677  ],\n",
              "       [1.2973    ],\n",
              "       [0.31125697],\n",
              "       [0.42800966],\n",
              "       [0.3001658 ],\n",
              "       [0.6489086 ],\n",
              "       [0.2366769 ],\n",
              "       [0.5873458 ],\n",
              "       [1.764693  ],\n",
              "       [0.7811411 ],\n",
              "       [0.9031832 ],\n",
              "       [2.5869045 ],\n",
              "       [0.8851681 ],\n",
              "       [1.1576678 ],\n",
              "       [1.419044  ],\n",
              "       [1.277272  ],\n",
              "       [0.33494148],\n",
              "       [0.17972073],\n",
              "       [0.18364957],\n",
              "       [0.16495952],\n",
              "       [1.6245288 ],\n",
              "       [0.12377663],\n",
              "       [0.14644724],\n",
              "       [0.8848498 ],\n",
              "       [0.6173626 ],\n",
              "       [0.26347604],\n",
              "       [0.8912994 ],\n",
              "       [0.69649035],\n",
              "       [0.75747895],\n",
              "       [0.30685362],\n",
              "       [0.31180286],\n",
              "       [0.31543562],\n",
              "       [0.41462013],\n",
              "       [0.24685363],\n",
              "       [1.0744327 ],\n",
              "       [0.8567529 ],\n",
              "       [0.39485425],\n",
              "       [1.059587  ],\n",
              "       [0.36303908],\n",
              "       [2.2485013 ],\n",
              "       [0.32720742],\n",
              "       [2.243688  ],\n",
              "       [0.2380538 ],\n",
              "       [2.9245706 ],\n",
              "       [2.2251482 ],\n",
              "       [0.16783406],\n",
              "       [1.4256681 ],\n",
              "       [0.3669751 ],\n",
              "       [2.7910023 ],\n",
              "       [0.6300145 ],\n",
              "       [0.1080773 ],\n",
              "       [2.7149954 ],\n",
              "       [0.5550816 ],\n",
              "       [0.7467803 ],\n",
              "       [1.1556035 ],\n",
              "       [0.24162999],\n",
              "       [0.8305711 ],\n",
              "       [0.16008714],\n",
              "       [0.35463983],\n",
              "       [0.6087055 ],\n",
              "       [0.48104092],\n",
              "       [0.77835906],\n",
              "       [0.8728271 ],\n",
              "       [0.48224452],\n",
              "       [3.0498285 ],\n",
              "       [0.65180475],\n",
              "       [0.19776335],\n",
              "       [1.027352  ],\n",
              "       [0.17463312],\n",
              "       [0.12032828],\n",
              "       [0.20184563],\n",
              "       [0.3784822 ],\n",
              "       [0.14090471],\n",
              "       [0.36104766],\n",
              "       [3.14004   ],\n",
              "       [0.91392344],\n",
              "       [0.29545367],\n",
              "       [0.21965137],\n",
              "       [0.90038866],\n",
              "       [0.30015913],\n",
              "       [0.46011195],\n",
              "       [0.89259136],\n",
              "       [0.37538666],\n",
              "       [0.37050155],\n",
              "       [0.33108804],\n",
              "       [1.0154403 ],\n",
              "       [2.5723672 ],\n",
              "       [0.514979  ],\n",
              "       [1.3008815 ],\n",
              "       [2.5765514 ],\n",
              "       [0.1694303 ],\n",
              "       [1.2128295 ],\n",
              "       [1.5874839 ],\n",
              "       [0.43954498],\n",
              "       [0.5088922 ],\n",
              "       [0.41812605],\n",
              "       [1.3563074 ],\n",
              "       [0.8080615 ],\n",
              "       [0.12578437],\n",
              "       [3.0453477 ],\n",
              "       [2.32768   ],\n",
              "       [2.2139142 ],\n",
              "       [0.168339  ],\n",
              "       [0.1585988 ],\n",
              "       [0.21038085],\n",
              "       [2.3023624 ],\n",
              "       [1.9968058 ],\n",
              "       [1.3163079 ],\n",
              "       [0.5985938 ],\n",
              "       [0.22107404],\n",
              "       [0.20718904],\n",
              "       [0.32568818],\n",
              "       [0.17686534],\n",
              "       [1.9567552 ],\n",
              "       [1.0524007 ],\n",
              "       [0.33116037],\n",
              "       [0.7682681 ],\n",
              "       [0.4746943 ],\n",
              "       [0.572311  ],\n",
              "       [0.38236383],\n",
              "       [0.14158729],\n",
              "       [0.14366743],\n",
              "       [1.3416268 ],\n",
              "       [1.2712764 ],\n",
              "       [2.6831093 ],\n",
              "       [0.20591712],\n",
              "       [1.1613424 ],\n",
              "       [0.1376496 ],\n",
              "       [0.9903203 ],\n",
              "       [2.9568121 ],\n",
              "       [0.97607833],\n",
              "       [0.47287562],\n",
              "       [0.2823178 ],\n",
              "       [0.53199124],\n",
              "       [0.92515886],\n",
              "       [0.5841207 ],\n",
              "       [0.33970535],\n",
              "       [0.56465966],\n",
              "       [2.3258626 ],\n",
              "       [0.16647038],\n",
              "       [0.24490386],\n",
              "       [0.4455845 ],\n",
              "       [3.0163362 ],\n",
              "       [0.71484673],\n",
              "       [2.9262505 ],\n",
              "       [0.46049687],\n",
              "       [0.13584107],\n",
              "       [0.55943125],\n",
              "       [0.18671177],\n",
              "       [0.374287  ],\n",
              "       [0.4163551 ],\n",
              "       [0.6997427 ],\n",
              "       [1.3866638 ],\n",
              "       [0.6408677 ],\n",
              "       [0.12025544],\n",
              "       [0.25689182],\n",
              "       [1.2510931 ],\n",
              "       [0.36309016],\n",
              "       [0.63548523],\n",
              "       [1.0915681 ],\n",
              "       [0.32078424],\n",
              "       [0.16623838],\n",
              "       [0.2534123 ],\n",
              "       [0.23635243],\n",
              "       [0.17350976],\n",
              "       [0.20380872],\n",
              "       [1.0981392 ],\n",
              "       [0.39302406],\n",
              "       [2.4878302 ],\n",
              "       [0.23652135],\n",
              "       [0.22255367],\n",
              "       [0.39551616],\n",
              "       [2.5331492 ],\n",
              "       [0.11416298],\n",
              "       [1.8872424 ],\n",
              "       [0.5343003 ],\n",
              "       [1.7655319 ],\n",
              "       [0.43312863],\n",
              "       [0.36657193],\n",
              "       [2.1376214 ],\n",
              "       [0.20432988],\n",
              "       [0.595016  ],\n",
              "       [0.732302  ],\n",
              "       [1.670158  ],\n",
              "       [0.40912938],\n",
              "       [0.43120435],\n",
              "       [0.34970167],\n",
              "       [0.19575104],\n",
              "       [0.9020538 ],\n",
              "       [0.39438805],\n",
              "       [0.13998184],\n",
              "       [2.3754015 ],\n",
              "       [0.2769433 ],\n",
              "       [0.20071064],\n",
              "       [2.7328815 ],\n",
              "       [0.13981108],\n",
              "       [1.138222  ],\n",
              "       [0.29930064],\n",
              "       [0.9298686 ],\n",
              "       [0.27871922],\n",
              "       [0.16679835],\n",
              "       [0.47975156],\n",
              "       [0.40545854],\n",
              "       [0.12014455],\n",
              "       [0.6879766 ],\n",
              "       [0.58163863],\n",
              "       [0.18932489],\n",
              "       [0.53318393],\n",
              "       [0.17851153],\n",
              "       [1.2833456 ],\n",
              "       [0.87074566],\n",
              "       [0.420611  ],\n",
              "       [0.19931863],\n",
              "       [2.6667452 ],\n",
              "       [2.5512729 ],\n",
              "       [0.56908107],\n",
              "       [0.21096471],\n",
              "       [0.8290969 ],\n",
              "       [0.43345606],\n",
              "       [0.3296863 ],\n",
              "       [0.7269333 ],\n",
              "       [0.5684866 ],\n",
              "       [0.50612456],\n",
              "       [0.21215943],\n",
              "       [3.247884  ],\n",
              "       [0.22432825],\n",
              "       [0.23204619],\n",
              "       [0.21070357],\n",
              "       [1.190231  ],\n",
              "       [0.7549546 ],\n",
              "       [2.1779275 ],\n",
              "       [0.4324068 ],\n",
              "       [0.08664395],\n",
              "       [0.86003435],\n",
              "       [0.6471566 ],\n",
              "       [0.3698817 ],\n",
              "       [1.1966058 ],\n",
              "       [0.47189042],\n",
              "       [0.39598164],\n",
              "       [1.1362227 ],\n",
              "       [2.2450137 ],\n",
              "       [0.23199728],\n",
              "       [0.36851618],\n",
              "       [1.3207878 ],\n",
              "       [2.3795452 ],\n",
              "       [0.45544106],\n",
              "       [0.24824551],\n",
              "       [0.78052825],\n",
              "       [0.30526486],\n",
              "       [0.5001909 ],\n",
              "       [2.9514308 ],\n",
              "       [1.2154242 ],\n",
              "       [0.31159398],\n",
              "       [2.2308855 ],\n",
              "       [0.7736032 ],\n",
              "       [0.41680655],\n",
              "       [0.21586405],\n",
              "       [0.20701227],\n",
              "       [0.71620303],\n",
              "       [1.351315  ],\n",
              "       [0.8033465 ],\n",
              "       [0.69996595],\n",
              "       [0.28073815],\n",
              "       [0.17965691],\n",
              "       [0.2117966 ],\n",
              "       [1.1589273 ],\n",
              "       [2.0378175 ],\n",
              "       [0.30198547],\n",
              "       [0.3047308 ],\n",
              "       [0.35001418],\n",
              "       [0.5561687 ],\n",
              "       [0.07876068],\n",
              "       [2.424766  ],\n",
              "       [0.30726978],\n",
              "       [0.68311703],\n",
              "       [1.0608028 ],\n",
              "       [0.576625  ],\n",
              "       [0.84496605],\n",
              "       [0.20299429],\n",
              "       [1.0601832 ],\n",
              "       [0.41538504],\n",
              "       [1.678857  ],\n",
              "       [0.7003467 ],\n",
              "       [0.5369966 ],\n",
              "       [3.3868337 ],\n",
              "       [0.74370825],\n",
              "       [0.17365572],\n",
              "       [0.21172714],\n",
              "       [0.4957219 ],\n",
              "       [0.44956222],\n",
              "       [0.3787474 ],\n",
              "       [3.311335  ],\n",
              "       [0.5995858 ],\n",
              "       [0.4898187 ],\n",
              "       [1.5639311 ],\n",
              "       [0.19524224],\n",
              "       [0.50636023],\n",
              "       [2.4309366 ],\n",
              "       [0.41166037],\n",
              "       [0.44218543],\n",
              "       [3.0484767 ],\n",
              "       [0.14341983],\n",
              "       [0.11974763]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHxo-oKkcPlx"
      },
      "source": [
        "predicted_offense_rating = predicted_offense_rating.flatten()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M0pvQYwcPRw",
        "outputId": "cb109d47-2aac-47ce-9cab-c3988ec5e39c"
      },
      "source": [
        "predicted_offense_rating"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.0271165 , 1.896576  , 2.1201699 , 3.2450128 , 1.7613202 ,\n",
              "       1.7344034 , 2.6720512 , 1.1171514 , 0.6002183 , 0.5154519 ,\n",
              "       0.33436006, 0.12961584, 1.124236  , 0.42192784, 0.7212789 ,\n",
              "       0.2723115 , 0.37618116, 2.1258643 , 0.319362  , 0.15746091,\n",
              "       0.37909022, 2.5595894 , 0.5490056 , 0.22213979, 0.6257827 ,\n",
              "       0.23107436, 0.19846725, 0.47175846, 0.77722335, 0.64708066,\n",
              "       0.19188762, 1.4412674 , 0.22845186, 0.6946441 , 0.35655954,\n",
              "       0.23574781, 2.3164427 , 2.7892802 , 0.14357847, 0.15241799,\n",
              "       1.6423002 , 0.3616983 , 0.43435806, 0.98469675, 0.89692354,\n",
              "       0.15364383, 0.41191095, 0.32432058, 0.1038937 , 0.8024137 ,\n",
              "       0.17779343, 0.6845093 , 0.17933166, 0.3659422 , 0.82341516,\n",
              "       1.0088638 , 0.33626768, 0.49635512, 1.4815007 , 0.31727186,\n",
              "       0.20426294, 0.7184721 , 2.4581704 , 0.84858996, 0.19902207,\n",
              "       0.2223233 , 0.83179986, 0.1372609 , 0.44449526, 0.20384356,\n",
              "       0.67849123, 0.4172039 , 1.7779578 , 0.38052392, 0.64846236,\n",
              "       0.24002549, 2.965106  , 0.21852635, 0.2515579 , 0.19377418,\n",
              "       0.2851989 , 1.7160257 , 0.4768445 , 0.505504  , 0.22690903,\n",
              "       0.4043936 , 2.700632  , 0.19521344, 0.28227547, 1.5091721 ,\n",
              "       3.2198412 , 2.362967  , 0.4485904 , 2.677055  , 0.4909415 ,\n",
              "       0.9374242 , 0.26108634, 0.71656424, 3.2034059 , 1.2136708 ,\n",
              "       0.44516003, 0.22842945, 0.2522289 , 0.4239993 , 0.3112078 ,\n",
              "       1.0492024 , 0.618349  , 0.46689737, 0.21531853, 2.9900718 ,\n",
              "       1.4368274 , 0.45198974, 0.4683835 , 0.48953304, 0.2526969 ,\n",
              "       0.3770381 , 0.30116177, 0.16823605, 0.54011726, 0.5908351 ,\n",
              "       0.6287879 , 0.20103435, 0.46424758, 0.13980414, 1.0170039 ,\n",
              "       0.1208317 , 0.26478115, 0.57108486, 1.2086372 , 0.1942943 ,\n",
              "       1.5560942 , 2.1169603 , 0.13946195, 0.19190083, 0.88436985,\n",
              "       0.29908225, 0.5445812 , 0.3048217 , 0.3440335 , 0.50359726,\n",
              "       0.20936996, 2.3203874 , 1.0454282 , 0.18510096, 2.6209497 ,\n",
              "       0.85112345, 0.29363576, 0.29016054, 0.94484794, 2.2091005 ,\n",
              "       0.60926807, 0.65890115, 0.31633788, 0.29248443, 1.4420679 ,\n",
              "       0.3988063 , 1.5563977 , 0.94197226, 0.7265014 , 0.15742032,\n",
              "       0.1920934 , 0.60265017, 0.27621624, 1.6643646 , 0.90581244,\n",
              "       0.812045  , 0.3316876 , 0.22237751, 2.9468207 , 2.7653909 ,\n",
              "       0.8232232 , 1.0639004 , 0.2266482 , 0.5491061 , 0.16575256,\n",
              "       0.7233842 , 1.6435063 , 0.43088314, 0.5155402 , 0.15113777,\n",
              "       2.0171032 , 0.4571538 , 0.17854498, 0.22228646, 1.5869248 ,\n",
              "       0.88403994, 0.32044277, 1.0565838 , 0.5141452 , 0.24464932,\n",
              "       0.56510127, 0.24601896, 0.77389073, 0.95155156, 0.38398048,\n",
              "       0.32633904, 0.41093495, 0.34233823, 0.4398754 , 0.45694503,\n",
              "       0.5338436 , 0.26439315, 1.0136153 , 0.30588797, 0.338971  ,\n",
              "       2.3116734 , 2.3738332 , 3.0181208 , 3.3189292 , 0.8708214 ,\n",
              "       1.1557661 , 3.196076  , 0.6520543 , 2.1191773 , 0.5884388 ,\n",
              "       0.6286407 , 0.4426485 , 0.81547046, 0.33259013, 0.18601993,\n",
              "       0.31000128, 2.9270802 , 0.47174132, 0.24985114, 0.34749156,\n",
              "       1.0216537 , 0.18828873, 2.0007799 , 0.47599384, 0.21082737,\n",
              "       2.6922054 , 3.4456172 , 2.8357024 , 1.3611253 , 0.24389592,\n",
              "       1.1636525 , 1.1429104 , 0.8837111 , 2.9385662 , 0.44850495,\n",
              "       2.2464647 , 0.15019926, 0.62009174, 0.2620964 , 1.2772306 ,\n",
              "       0.52257866, 0.77738565, 1.0574967 , 0.11947341, 0.2387808 ,\n",
              "       0.22058298, 0.24525148, 2.6971679 , 0.22846949, 0.23530723,\n",
              "       0.3844706 , 0.18427204, 0.28315866, 0.31059024, 0.7963013 ,\n",
              "       0.6763817 , 0.38032725, 0.21170281, 0.32498732, 2.931019  ,\n",
              "       0.46051666, 0.50982827, 1.1008934 , 0.35798708, 0.30106035,\n",
              "       0.13091178, 0.44736287, 0.23391807, 1.2622005 , 0.29961625,\n",
              "       0.16312158, 1.7706331 , 2.8679054 , 0.07851921, 0.14355995,\n",
              "       0.2516204 , 0.37446216, 0.90643835, 2.1838624 , 0.30885744,\n",
              "       1.262173  , 1.471939  , 0.8529843 , 3.3108048 , 0.40335557,\n",
              "       0.65889734, 1.9313394 , 0.36313346, 0.4514331 , 0.30700836,\n",
              "       3.0560951 , 0.26499265, 0.6887171 , 0.54498994, 0.51430434,\n",
              "       0.3074169 , 1.751155  , 1.3855118 , 0.80679077, 1.3948892 ,\n",
              "       0.6953784 , 2.193581  , 0.3634752 , 1.5497786 , 0.757398  ,\n",
              "       0.17536235, 1.4980116 , 0.67885333, 0.2899495 , 0.4457927 ,\n",
              "       0.14954205, 0.9542153 , 0.28191474, 0.42625758, 0.39706767,\n",
              "       0.29267693, 1.9868779 , 0.1213617 , 0.6614335 , 0.45285544,\n",
              "       0.5141548 , 0.49638832, 0.315141  , 0.4953814 , 0.7396157 ,\n",
              "       0.16157112, 0.62014997, 2.682142  , 0.40031448, 2.903593  ,\n",
              "       1.9192668 , 1.8227551 , 1.123481  , 0.41934124, 1.4028753 ,\n",
              "       1.0381314 , 0.49553367, 0.29053822, 1.609689  , 0.28598374,\n",
              "       0.7787446 , 0.21077695, 0.18491435, 1.2989001 , 2.7553115 ,\n",
              "       0.3722776 , 1.2978777 , 0.38300803, 0.5501648 , 2.5374649 ,\n",
              "       0.6002908 , 0.48659837, 0.30791935, 0.36524162, 0.6253863 ,\n",
              "       1.8739504 , 0.18898839, 0.319759  , 0.42347047, 0.13863844,\n",
              "       0.139138  , 0.4885184 , 0.23147199, 1.0323231 , 2.838278  ,\n",
              "       1.465859  , 1.7169571 , 0.20218101, 0.17506674, 0.79160416,\n",
              "       2.0129554 , 0.23820636, 1.1895021 , 0.44384405, 0.34214035,\n",
              "       0.28396052, 1.6166738 , 1.4842418 , 0.15395592, 0.24810916,\n",
              "       0.32417968, 0.39263234, 2.8972762 , 0.17178766, 1.3191074 ,\n",
              "       1.489968  , 1.3120598 , 0.32740006, 0.67380416, 0.33706316,\n",
              "       0.4245316 , 0.5472423 , 0.166072  , 2.673592  , 0.4455845 ,\n",
              "       1.404143  , 1.9622818 , 2.657781  , 3.020989  , 0.21293104,\n",
              "       0.8569104 , 0.7188083 , 2.1550498 , 0.7914973 , 0.46535388,\n",
              "       0.19166039, 0.38533953, 1.7988707 , 1.609245  , 0.6601069 ,\n",
              "       1.8062236 , 0.26763165, 0.3868189 , 2.6062553 , 0.49691775,\n",
              "       3.0006928 , 0.21427861, 0.33893207, 0.48547187, 0.71511596,\n",
              "       0.20363207, 0.47951147, 0.19606528, 0.58471185, 0.2032049 ,\n",
              "       0.2875802 , 0.22773407, 1.7943202 , 0.6081048 , 0.34866485,\n",
              "       0.24802339, 3.3238623 , 1.3079907 , 2.6375833 , 0.68519163,\n",
              "       0.7964823 , 0.22966409, 0.59015906, 0.823544  , 0.14549853,\n",
              "       0.49202424, 0.17183094, 0.3646722 , 1.9157767 , 1.7326578 ,\n",
              "       2.132223  , 0.35457948, 0.33215097, 0.18342832, 2.1218452 ,\n",
              "       0.6644008 , 1.9758407 , 1.2842206 , 0.8189064 , 0.14481582,\n",
              "       0.57081735, 0.9774926 , 0.3347932 , 0.4273176 , 0.29069722,\n",
              "       0.37259096, 0.27954984, 0.30092666, 0.33111128, 2.2358952 ,\n",
              "       0.7008424 , 0.30285773, 0.19831711, 0.3341631 , 0.63176215,\n",
              "       0.12775092, 0.16170174, 0.68508387, 2.1941676 , 0.29392934,\n",
              "       1.8392037 , 0.5985247 , 1.5797747 , 0.67681193, 0.27074736,\n",
              "       0.5101922 , 3.1064258 , 1.4159106 , 0.28344205, 0.4708858 ,\n",
              "       0.18598957, 0.9939339 , 0.4716154 , 0.34347844, 2.2208588 ,\n",
              "       2.5473442 , 0.6003206 , 1.3604574 , 0.18863449, 2.8123121 ,\n",
              "       0.3031968 , 0.92415816, 2.7024598 , 0.31736144, 1.4525307 ,\n",
              "       1.6475747 , 0.6047802 , 2.9914474 , 0.81766814, 0.25086433,\n",
              "       0.2011062 , 1.1095632 , 0.1685859 , 0.52965486, 0.31062275,\n",
              "       0.6173116 , 0.73313373, 0.3545064 , 0.2212192 , 0.47443664,\n",
              "       0.8438908 , 0.5016353 , 0.7163888 , 0.38279757, 0.32109877,\n",
              "       1.2427822 , 0.15823773, 1.4183882 , 0.5860263 , 0.2662115 ,\n",
              "       0.668152  , 1.8394731 , 0.15958802, 2.126411  , 0.85794926,\n",
              "       0.61751056, 3.1355186 , 0.34793177, 0.61916417, 0.22245413,\n",
              "       3.276657  , 0.88653004, 2.549078  , 0.8760294 , 0.38436416,\n",
              "       0.34440827, 2.6321049 , 0.9633766 , 0.29620174, 0.24302238,\n",
              "       0.37330687, 2.4860518 , 0.568507  , 2.89194   , 0.65569603,\n",
              "       0.1790892 , 1.195871  , 0.45701995, 0.19737484, 0.63830566,\n",
              "       0.8363475 , 0.2311045 , 0.1501156 , 0.759225  , 0.31231907,\n",
              "       0.23914392, 0.35866627, 1.7331831 , 2.881639  , 1.1124386 ,\n",
              "       0.12129939, 1.5478631 , 0.15716438, 0.42191228, 0.37905967,\n",
              "       0.27403715, 0.950551  , 0.9911299 , 0.6897536 , 0.352591  ,\n",
              "       1.4466686 , 0.175662  , 2.5096624 , 3.0660462 , 0.65837437,\n",
              "       0.24866691, 0.20864305, 0.19765168, 0.22432825, 0.34437504,\n",
              "       1.018715  , 0.56330454, 2.305974  , 2.3810568 , 0.71465117,\n",
              "       1.6669612 , 0.12792176, 0.30206987, 1.5469536 , 3.073663  ,\n",
              "       0.5268405 , 0.16967526, 0.1866472 , 0.48601976, 0.46863857,\n",
              "       0.20020159, 0.9762627 , 0.9925358 , 0.34352234, 0.27383837,\n",
              "       0.4054937 , 0.70717406, 1.0406691 , 0.37070733, 0.38710698,\n",
              "       0.30575195, 0.29040816, 0.85210353, 1.6015793 , 1.0382241 ,\n",
              "       0.17214814, 1.5303243 , 0.1650632 , 0.3154431 , 0.27868596,\n",
              "       0.68364346, 1.0561563 , 1.9263862 , 1.0239561 , 0.2604644 ,\n",
              "       1.1703581 , 1.8516737 , 0.8904301 , 0.2811065 , 0.12931086,\n",
              "       0.56813335, 1.5639313 , 0.37413672, 1.5300952 , 3.0694346 ,\n",
              "       0.30270818, 2.3252187 , 0.17110525, 0.5171244 , 0.2980555 ,\n",
              "       2.4910092 , 1.368339  , 0.45702282, 2.6672356 , 1.0397052 ,\n",
              "       0.18290974, 0.25779653, 2.4222078 , 0.72523534, 0.21714854,\n",
              "       0.37309092, 2.2601447 , 0.35660407, 0.56190145, 0.28085127,\n",
              "       2.9955034 , 2.6137323 , 0.1347381 , 0.2206693 , 0.28335255,\n",
              "       2.1892164 , 1.2667563 , 0.53437924, 1.3414953 , 0.72907686,\n",
              "       1.2017989 , 0.71783197, 0.35090402, 1.982381  , 1.139278  ,\n",
              "       0.24044955, 3.1215825 , 0.623162  , 2.3626206 , 0.14969558,\n",
              "       0.6158854 , 0.5122527 , 2.9675827 , 1.6752931 , 0.4480295 ,\n",
              "       0.76552606, 0.18142575, 0.26442152, 0.8182821 , 0.20726427,\n",
              "       0.1576922 , 0.14061767, 0.62672126, 1.5828301 , 0.19237892,\n",
              "       2.7400756 , 1.6413289 , 2.335677  , 1.2973    , 0.31125697,\n",
              "       0.42800966, 0.3001658 , 0.6489086 , 0.2366769 , 0.5873458 ,\n",
              "       1.764693  , 0.7811411 , 0.9031832 , 2.5869045 , 0.8851681 ,\n",
              "       1.1576678 , 1.419044  , 1.277272  , 0.33494148, 0.17972073,\n",
              "       0.18364957, 0.16495952, 1.6245288 , 0.12377663, 0.14644724,\n",
              "       0.8848498 , 0.6173626 , 0.26347604, 0.8912994 , 0.69649035,\n",
              "       0.75747895, 0.30685362, 0.31180286, 0.31543562, 0.41462013,\n",
              "       0.24685363, 1.0744327 , 0.8567529 , 0.39485425, 1.059587  ,\n",
              "       0.36303908, 2.2485013 , 0.32720742, 2.243688  , 0.2380538 ,\n",
              "       2.9245706 , 2.2251482 , 0.16783406, 1.4256681 , 0.3669751 ,\n",
              "       2.7910023 , 0.6300145 , 0.1080773 , 2.7149954 , 0.5550816 ,\n",
              "       0.7467803 , 1.1556035 , 0.24162999, 0.8305711 , 0.16008714,\n",
              "       0.35463983, 0.6087055 , 0.48104092, 0.77835906, 0.8728271 ,\n",
              "       0.48224452, 3.0498285 , 0.65180475, 0.19776335, 1.027352  ,\n",
              "       0.17463312, 0.12032828, 0.20184563, 0.3784822 , 0.14090471,\n",
              "       0.36104766, 3.14004   , 0.91392344, 0.29545367, 0.21965137,\n",
              "       0.90038866, 0.30015913, 0.46011195, 0.89259136, 0.37538666,\n",
              "       0.37050155, 0.33108804, 1.0154403 , 2.5723672 , 0.514979  ,\n",
              "       1.3008815 , 2.5765514 , 0.1694303 , 1.2128295 , 1.5874839 ,\n",
              "       0.43954498, 0.5088922 , 0.41812605, 1.3563074 , 0.8080615 ,\n",
              "       0.12578437, 3.0453477 , 2.32768   , 2.2139142 , 0.168339  ,\n",
              "       0.1585988 , 0.21038085, 2.3023624 , 1.9968058 , 1.3163079 ,\n",
              "       0.5985938 , 0.22107404, 0.20718904, 0.32568818, 0.17686534,\n",
              "       1.9567552 , 1.0524007 , 0.33116037, 0.7682681 , 0.4746943 ,\n",
              "       0.572311  , 0.38236383, 0.14158729, 0.14366743, 1.3416268 ,\n",
              "       1.2712764 , 2.6831093 , 0.20591712, 1.1613424 , 0.1376496 ,\n",
              "       0.9903203 , 2.9568121 , 0.97607833, 0.47287562, 0.2823178 ,\n",
              "       0.53199124, 0.92515886, 0.5841207 , 0.33970535, 0.56465966,\n",
              "       2.3258626 , 0.16647038, 0.24490386, 0.4455845 , 3.0163362 ,\n",
              "       0.71484673, 2.9262505 , 0.46049687, 0.13584107, 0.55943125,\n",
              "       0.18671177, 0.374287  , 0.4163551 , 0.6997427 , 1.3866638 ,\n",
              "       0.6408677 , 0.12025544, 0.25689182, 1.2510931 , 0.36309016,\n",
              "       0.63548523, 1.0915681 , 0.32078424, 0.16623838, 0.2534123 ,\n",
              "       0.23635243, 0.17350976, 0.20380872, 1.0981392 , 0.39302406,\n",
              "       2.4878302 , 0.23652135, 0.22255367, 0.39551616, 2.5331492 ,\n",
              "       0.11416298, 1.8872424 , 0.5343003 , 1.7655319 , 0.43312863,\n",
              "       0.36657193, 2.1376214 , 0.20432988, 0.595016  , 0.732302  ,\n",
              "       1.670158  , 0.40912938, 0.43120435, 0.34970167, 0.19575104,\n",
              "       0.9020538 , 0.39438805, 0.13998184, 2.3754015 , 0.2769433 ,\n",
              "       0.20071064, 2.7328815 , 0.13981108, 1.138222  , 0.29930064,\n",
              "       0.9298686 , 0.27871922, 0.16679835, 0.47975156, 0.40545854,\n",
              "       0.12014455, 0.6879766 , 0.58163863, 0.18932489, 0.53318393,\n",
              "       0.17851153, 1.2833456 , 0.87074566, 0.420611  , 0.19931863,\n",
              "       2.6667452 , 2.5512729 , 0.56908107, 0.21096471, 0.8290969 ,\n",
              "       0.43345606, 0.3296863 , 0.7269333 , 0.5684866 , 0.50612456,\n",
              "       0.21215943, 3.247884  , 0.22432825, 0.23204619, 0.21070357,\n",
              "       1.190231  , 0.7549546 , 2.1779275 , 0.4324068 , 0.08664395,\n",
              "       0.86003435, 0.6471566 , 0.3698817 , 1.1966058 , 0.47189042,\n",
              "       0.39598164, 1.1362227 , 2.2450137 , 0.23199728, 0.36851618,\n",
              "       1.3207878 , 2.3795452 , 0.45544106, 0.24824551, 0.78052825,\n",
              "       0.30526486, 0.5001909 , 2.9514308 , 1.2154242 , 0.31159398,\n",
              "       2.2308855 , 0.7736032 , 0.41680655, 0.21586405, 0.20701227,\n",
              "       0.71620303, 1.351315  , 0.8033465 , 0.69996595, 0.28073815,\n",
              "       0.17965691, 0.2117966 , 1.1589273 , 2.0378175 , 0.30198547,\n",
              "       0.3047308 , 0.35001418, 0.5561687 , 0.07876068, 2.424766  ,\n",
              "       0.30726978, 0.68311703, 1.0608028 , 0.576625  , 0.84496605,\n",
              "       0.20299429, 1.0601832 , 0.41538504, 1.678857  , 0.7003467 ,\n",
              "       0.5369966 , 3.3868337 , 0.74370825, 0.17365572, 0.21172714,\n",
              "       0.4957219 , 0.44956222, 0.3787474 , 3.311335  , 0.5995858 ,\n",
              "       0.4898187 , 1.5639311 , 0.19524224, 0.50636023, 2.4309366 ,\n",
              "       0.41166037, 0.44218543, 3.0484767 , 0.14341983, 0.11974763],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFydBac9Ny5W"
      },
      "source": [
        "submit=pd.DataFrame({'id':df_test['id'].values.tolist(),'is_humor':predicted, \n",
        "                     'humor_rating':predicted_humor_rating, 'humor_controversy':predicted_contro,\n",
        "                     'offense_rating':predicted_offense_rating})"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "Lgq6rGyfZsYb",
        "outputId": "fdf00c59-50de-47d8-a4d4-31758a1e8358"
      },
      "source": [
        "submit"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_controversy</th>\n",
              "      <th>offense_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8001</td>\n",
              "      <td>1</td>\n",
              "      <td>1.026728</td>\n",
              "      <td>1</td>\n",
              "      <td>3.027117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8002</td>\n",
              "      <td>1</td>\n",
              "      <td>1.028560</td>\n",
              "      <td>0</td>\n",
              "      <td>1.896576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8003</td>\n",
              "      <td>1</td>\n",
              "      <td>1.028157</td>\n",
              "      <td>0</td>\n",
              "      <td>2.120170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8004</td>\n",
              "      <td>1</td>\n",
              "      <td>1.027142</td>\n",
              "      <td>0</td>\n",
              "      <td>3.245013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8005</td>\n",
              "      <td>1</td>\n",
              "      <td>1.028117</td>\n",
              "      <td>0</td>\n",
              "      <td>1.761320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>8996</td>\n",
              "      <td>1</td>\n",
              "      <td>1.028061</td>\n",
              "      <td>0</td>\n",
              "      <td>0.411660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>8997</td>\n",
              "      <td>1</td>\n",
              "      <td>1.030412</td>\n",
              "      <td>0</td>\n",
              "      <td>0.442185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>8998</td>\n",
              "      <td>1</td>\n",
              "      <td>1.029823</td>\n",
              "      <td>0</td>\n",
              "      <td>3.048477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>8999</td>\n",
              "      <td>1</td>\n",
              "      <td>1.020417</td>\n",
              "      <td>0</td>\n",
              "      <td>0.143420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>9000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.026742</td>\n",
              "      <td>0</td>\n",
              "      <td>0.119748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows  5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  is_humor  humor_rating  humor_controversy  offense_rating\n",
              "0    8001         1      1.026728                  1        3.027117\n",
              "1    8002         1      1.028560                  0        1.896576\n",
              "2    8003         1      1.028157                  0        2.120170\n",
              "3    8004         1      1.027142                  0        3.245013\n",
              "4    8005         1      1.028117                  0        1.761320\n",
              "..    ...       ...           ...                ...             ...\n",
              "995  8996         1      1.028061                  0        0.411660\n",
              "996  8997         1      1.030412                  0        0.442185\n",
              "997  8998         1      1.029823                  0        3.048477\n",
              "998  8999         1      1.020417                  0        0.143420\n",
              "999  9000         1      1.026742                  0        0.119748\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQvMXYRfN_gW"
      },
      "source": [
        "submit.to_csv('submission_300_all.csv', index=False)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojrf-Ls-ZwQF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}